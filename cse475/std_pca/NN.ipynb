{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Create your first MLP in Keras\n",
    "import time\n",
    "start = time.time()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"diabetes\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nazmus Sakib\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nazmus Sakib\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 2.2910 - acc: 0.6094\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.7640 - acc: 0.6458\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.7067 - acc: 0.6563\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.6751 - acc: 0.6680\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.6633 - acc: 0.6732\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.6385 - acc: 0.6966\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.6466 - acc: 0.6901\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 197us/step - loss: 0.6231 - acc: 0.6862\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.6327 - acc: 0.6823\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.6013 - acc: 0.6979\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 239us/step - loss: 0.6066 - acc: 0.7005\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.6030 - acc: 0.7057\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5792 - acc: 0.7057\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.6006 - acc: 0.6927\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 257us/step - loss: 0.5993 - acc: 0.6953\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 259us/step - loss: 0.5885 - acc: 0.6823\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.5781 - acc: 0.7005\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5654 - acc: 0.7005\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5677 - acc: 0.7070\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5654 - acc: 0.6992\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5519 - acc: 0.7214\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 225us/step - loss: 0.5509 - acc: 0.7292\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 230us/step - loss: 0.5545 - acc: 0.7318\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5526 - acc: 0.7292\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.5370 - acc: 0.7500\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 243us/step - loss: 0.5448 - acc: 0.7266\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 223us/step - loss: 0.5279 - acc: 0.7448\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 226us/step - loss: 0.5372 - acc: 0.7344\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5242 - acc: 0.7435\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 254us/step - loss: 0.5191 - acc: 0.7383\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 249us/step - loss: 0.5361 - acc: 0.7161\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 250us/step - loss: 0.5279 - acc: 0.7604\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 239us/step - loss: 0.5229 - acc: 0.7435\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5302 - acc: 0.7435\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.5204 - acc: 0.7461\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5148 - acc: 0.7500\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 216us/step - loss: 0.5059 - acc: 0.7565\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.5109 - acc: 0.7422\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.5098 - acc: 0.7539\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5085 - acc: 0.7500\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 193us/step - loss: 0.5092 - acc: 0.7604\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.5204 - acc: 0.7448\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.4949 - acc: 0.7760\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.4988 - acc: 0.7643\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.4986 - acc: 0.7682\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.5130 - acc: 0.7617\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 211us/step - loss: 0.5001 - acc: 0.7461\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 204us/step - loss: 0.5054 - acc: 0.7578\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 193us/step - loss: 0.5034 - acc: 0.7409\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5057 - acc: 0.7474\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 193us/step - loss: 0.5011 - acc: 0.7617\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5026 - acc: 0.7500\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.5031 - acc: 0.7630\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.5034 - acc: 0.7487\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 164us/step - loss: 0.5003 - acc: 0.7695\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.4998 - acc: 0.7682\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.4990 - acc: 0.7682\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 166us/step - loss: 0.4837 - acc: 0.7682\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 167us/step - loss: 0.4877 - acc: 0.7669\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 167us/step - loss: 0.4936 - acc: 0.7708\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.4892 - acc: 0.7669\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.4856 - acc: 0.7708\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4952 - acc: 0.7656\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4908 - acc: 0.7539\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.4852 - acc: 0.7656\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 176us/step - loss: 0.4857 - acc: 0.7682\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 165us/step - loss: 0.4858 - acc: 0.7630\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.4892 - acc: 0.7682\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.4824 - acc: 0.7565\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.4927 - acc: 0.7513\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4799 - acc: 0.7708\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4852 - acc: 0.7786\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4868 - acc: 0.7539\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 230us/step - loss: 0.4891 - acc: 0.7604\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4810 - acc: 0.7669\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.4817 - acc: 0.7773\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.4803 - acc: 0.7630\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.4814 - acc: 0.7760\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 193us/step - loss: 0.4834 - acc: 0.7721\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4778 - acc: 0.7786\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.4735 - acc: 0.7656\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 179us/step - loss: 0.4644 - acc: 0.7721\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.4673 - acc: 0.7812\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 160us/step - loss: 0.4676 - acc: 0.7773\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 164us/step - loss: 0.4790 - acc: 0.7695\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.4831 - acc: 0.7604\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4744 - acc: 0.7630\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.4699 - acc: 0.7734\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.4712 - acc: 0.7812\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.4758 - acc: 0.7643\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4695 - acc: 0.7721\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.4710 - acc: 0.7812\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.4681 - acc: 0.7760\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.4663 - acc: 0.7734\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 162us/step - loss: 0.4729 - acc: 0.7760\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4687 - acc: 0.7747\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 199us/step - loss: 0.4657 - acc: 0.7917\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4674 - acc: 0.7695\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 167us/step - loss: 0.4594 - acc: 0.7734\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 161us/step - loss: 0.4654 - acc: 0.7878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea8eba04a8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 29us/step\n",
      "\n",
      "acc: 79.6875%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "#print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "#feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "#feat_importances.nlargest(10).plot(kind='barh')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155.09008026123047\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_bmi = dataset['BMI'].std()\n",
    "dataset['BMI'] = dataset['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)\n",
    "\n",
    "median_bloodp = dataset['BloodPressure'].std()\n",
    "dataset['BloodPressure'] = dataset['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)\n",
    "\n",
    "median_plglcconc = dataset['Glucose'].std()\n",
    "dataset['Glucose'] = dataset['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)\n",
    "\n",
    "median_skinthick = dataset['SkinThickness'].std()\n",
    "dataset['SkinThickness'] = dataset['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)\n",
    "\n",
    "median_Insulin = dataset['Insulin'].std()\n",
    "dataset['Insulin'] = dataset['Insulin'].replace(\n",
    "    to_replace=0, value=median_Insulin)\n",
    "\n",
    "median_DiabetesPedigreeFunction = dataset['DiabetesPedigreeFunction'].std()\n",
    "dataset['DiabetesPedigreeFunction'] = dataset['DiabetesPedigreeFunction'].replace(\n",
    "    to_replace=0, value=median_DiabetesPedigreeFunction)\n",
    "\n",
    "median_Age = dataset['Age'].std()\n",
    "dataset['Age'] = dataset['Age'].replace(\n",
    "    to_replace=0, value=median_Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness     Insulin   BMI  \\\n",
       "0            6    148.0           72.0      35.000000  115.244002  33.6   \n",
       "1            1     85.0           66.0      29.000000  115.244002  26.6   \n",
       "2            8    183.0           64.0      15.952218  115.244002  23.3   \n",
       "3            1     89.0           66.0      23.000000   94.000000  28.1   \n",
       "4            0    137.0           40.0      35.000000  168.000000  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"diabetes_impute_std.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_impute_std.txt\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 4.6899 - acc: 0.4740\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.8663 - acc: 0.5768\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 215us/step - loss: 0.7361 - acc: 0.6081\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.6688 - acc: 0.6510\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.6327 - acc: 0.6810\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.6220 - acc: 0.6745\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6111 - acc: 0.6797\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 198us/step - loss: 0.5934 - acc: 0.7057\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5882 - acc: 0.7018\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 307us/step - loss: 0.6015 - acc: 0.6992\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 534us/step - loss: 0.5694 - acc: 0.7005\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.5794 - acc: 0.7031\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5710 - acc: 0.7148\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 254us/step - loss: 0.5633 - acc: 0.7174\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 243us/step - loss: 0.5620 - acc: 0.7161\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5548 - acc: 0.7227\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5592 - acc: 0.7070\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5538 - acc: 0.7174 0s - loss: 0.5522 - acc: 0.7\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 246us/step - loss: 0.5539 - acc: 0.7083\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 243us/step - loss: 0.5486 - acc: 0.7227\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5494 - acc: 0.7318\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.5414 - acc: 0.7266\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 158us/step - loss: 0.5415 - acc: 0.7370\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5452 - acc: 0.7318\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.5405 - acc: 0.7383\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.5456 - acc: 0.7318\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.5312 - acc: 0.7240\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5424 - acc: 0.7201\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5311 - acc: 0.7396\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.5310 - acc: 0.7344\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.5297 - acc: 0.7370\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.5277 - acc: 0.7318\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.5188 - acc: 0.7448\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.5360 - acc: 0.7266\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5340 - acc: 0.7344\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.5225 - acc: 0.7292\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.5271 - acc: 0.7396\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5230 - acc: 0.7409\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5231 - acc: 0.7409\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5233 - acc: 0.7448\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5156 - acc: 0.7331\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5184 - acc: 0.7552\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5128 - acc: 0.7578\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5098 - acc: 0.7526\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5126 - acc: 0.7396\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.5156 - acc: 0.7578\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5115 - acc: 0.7513\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5073 - acc: 0.7474\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5155 - acc: 0.7448\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.5114 - acc: 0.7487\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5090 - acc: 0.7409\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5087 - acc: 0.7630\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 355us/step - loss: 0.5086 - acc: 0.7422\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5040 - acc: 0.7422\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.5062 - acc: 0.7487\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 522us/step - loss: 0.5044 - acc: 0.7474\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 536us/step - loss: 0.5060 - acc: 0.7513\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 340us/step - loss: 0.5007 - acc: 0.7461\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5110 - acc: 0.7448\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.5069 - acc: 0.7448 0s - loss: 0.5079 - acc: 0.74\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5029 - acc: 0.7604\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.5033 - acc: 0.7617\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 227us/step - loss: 0.4975 - acc: 0.7435\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.5050 - acc: 0.7552\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5030 - acc: 0.7448 0s - loss: 0.4734 - acc: 0.7\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.4930 - acc: 0.7461\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.4901 - acc: 0.7513\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.4998 - acc: 0.7474\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 267us/step - loss: 0.4890 - acc: 0.7526\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.4963 - acc: 0.7474\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 267us/step - loss: 0.4919 - acc: 0.7461\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.4959 - acc: 0.7617\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 254us/step - loss: 0.4939 - acc: 0.7435\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 228us/step - loss: 0.4970 - acc: 0.7500\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.4930 - acc: 0.7539\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.4844 - acc: 0.7526\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.4916 - acc: 0.7487\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.4911 - acc: 0.7435\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 209us/step - loss: 0.4904 - acc: 0.7669\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 188us/step - loss: 0.4894 - acc: 0.7552\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.4894 - acc: 0.7552\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.4844 - acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4874 - acc: 0.7539\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.4809 - acc: 0.7604\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.4867 - acc: 0.7630\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.4825 - acc: 0.7448\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.4814 - acc: 0.7656\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.4822 - acc: 0.7591\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4788 - acc: 0.7539\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.4784 - acc: 0.7630\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.4770 - acc: 0.7630\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.4779 - acc: 0.7604\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.4758 - acc: 0.7630\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.4686 - acc: 0.764 - 0s 195us/step - loss: 0.4753 - acc: 0.7591\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.4781 - acc: 0.7526\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.4759 - acc: 0.7604\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.4736 - acc: 0.7656\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.4784 - acc: 0.7669\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 209us/step - loss: 0.4676 - acc: 0.7552\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.4774 - acc: 0.7630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea87b4c7b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 235us/step\n",
      "\n",
      "acc: 77.0833%\n",
      "26.31741428375244\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## impute in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-15.46505896 -32.15983414]\n",
      " [-26.35415787  32.55551479]\n",
      " [-10.77178388 -61.45464328]\n",
      " ...\n",
      " [-23.77110352  -3.39778147]\n",
      " [-19.82236876  -8.06381502]\n",
      " [-24.98538077  25.04875082]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy\n",
    "start = time.time()\n",
    "dataset = numpy.loadtxt(\"diabetes_impute_std.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.7444 - acc: 0.6029\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.6416 - acc: 0.6497\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.6261 - acc: 0.6523\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.6204 - acc: 0.6510\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.6146 - acc: 0.6510\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.6161 - acc: 0.6510\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.6111 - acc: 0.6523\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 215us/step - loss: 0.6203 - acc: 0.6510\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.6076 - acc: 0.6497\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.6080 - acc: 0.6523\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.6014 - acc: 0.6523\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.6103 - acc: 0.6523\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.6028 - acc: 0.6497\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.6022 - acc: 0.6536\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.6035 - acc: 0.6523\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.6021 - acc: 0.6523\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.6024 - acc: 0.6536\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5958 - acc: 0.6536\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 248us/step - loss: 0.5947 - acc: 0.6536\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5972 - acc: 0.6523\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.5981 - acc: 0.6523\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5972 - acc: 0.6510\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5951 - acc: 0.6523 0s - loss: 0.5506 - acc: 0.69\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5958 - acc: 0.6523\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5928 - acc: 0.6523\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5982 - acc: 0.6497\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5894 - acc: 0.6536\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5945 - acc: 0.6536\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5941 - acc: 0.6536\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5932 - acc: 0.6536 0s - loss: 0.5951 - acc: 0.644\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5948 - acc: 0.6523\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5896 - acc: 0.6523\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5891 - acc: 0.6536\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5917 - acc: 0.6510\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.5936 - acc: 0.6523\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5874 - acc: 0.6536\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.5914 - acc: 0.6536\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5959 - acc: 0.6523\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.5878 - acc: 0.6536\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5844 - acc: 0.6523\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5859 - acc: 0.6536\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5868 - acc: 0.6536\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5889 - acc: 0.6536\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.5915 - acc: 0.6523\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.5899 - acc: 0.6536\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5874 - acc: 0.6680\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5878 - acc: 0.6563\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5914 - acc: 0.6497\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5836 - acc: 0.6536\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 248us/step - loss: 0.5820 - acc: 0.7070\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5906 - acc: 0.6953\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5842 - acc: 0.7148\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5834 - acc: 0.6992\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5827 - acc: 0.7174\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5867 - acc: 0.6862\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5842 - acc: 0.7031\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5875 - acc: 0.6992\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5820 - acc: 0.6888\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5826 - acc: 0.6992\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5839 - acc: 0.7018\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.5803 - acc: 0.7005\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5832 - acc: 0.7044 0s - loss: 0.6108 - acc: 0.70\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5820 - acc: 0.6979\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5864 - acc: 0.7070\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5835 - acc: 0.7057\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5812 - acc: 0.6914\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5791 - acc: 0.6992\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.5780 - acc: 0.6979\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5900 - acc: 0.6992\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5803 - acc: 0.6966\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5780 - acc: 0.7227\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5800 - acc: 0.7018\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.5806 - acc: 0.7044\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 176us/step - loss: 0.5784 - acc: 0.6914\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.5756 - acc: 0.6888\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5797 - acc: 0.6953\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.5823 - acc: 0.7083\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 237us/step - loss: 0.5768 - acc: 0.6992\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 245us/step - loss: 0.5787 - acc: 0.7018\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5801 - acc: 0.7083\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.5730 - acc: 0.7096\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5881 - acc: 0.6901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 209us/step - loss: 0.5732 - acc: 0.7174\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.5767 - acc: 0.7018\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5790 - acc: 0.7174\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5783 - acc: 0.6979\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.5757 - acc: 0.6966\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.5756 - acc: 0.7122\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5806 - acc: 0.7188\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5785 - acc: 0.7148\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 222us/step - loss: 0.5762 - acc: 0.7057\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5731 - acc: 0.7083\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 209us/step - loss: 0.5713 - acc: 0.7135\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5746 - acc: 0.7070\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5658 - acc: 0.7044\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.5723 - acc: 0.7070\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.5738 - acc: 0.7188\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.5758 - acc: 0.7122\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5669 - acc: 0.7135\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5722 - acc: 0.7148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea92b70860>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 234us/step\n",
      "\n",
      "acc: 70.4427%\n",
      "22.270019054412842\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.impute & scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')\n",
    "start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nazmus Sakib\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "median_bmi = dataset['BMI'].std()\n",
    "dataset['BMI'] = dataset['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)\n",
    "\n",
    "median_bloodp = dataset['BloodPressure'].std()\n",
    "dataset['BloodPressure'] = dataset['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)\n",
    "\n",
    "median_plglcconc = dataset['Glucose'].std()\n",
    "dataset['Glucose'] = dataset['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)\n",
    "\n",
    "median_skinthick = dataset['SkinThickness'].std()\n",
    "dataset['SkinThickness'] = dataset['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)\n",
    "\n",
    "median_Insulin = dataset['Insulin'].std()\n",
    "dataset['Insulin'] = dataset['Insulin'].replace(\n",
    "    to_replace=0, value=median_Insulin)\n",
    "\n",
    "median_DiabetesPedigreeFunction = dataset['DiabetesPedigreeFunction'].std()\n",
    "dataset['DiabetesPedigreeFunction'] = dataset['DiabetesPedigreeFunction'].replace(\n",
    "    to_replace=0, value=median_DiabetesPedigreeFunction)\n",
    "\n",
    "median_Age = dataset['Age'].std()\n",
    "dataset['Age'] = dataset['Age'].replace(\n",
    "    to_replace=0, value=median_Age)\n",
    "\n",
    "\n",
    "y = dataset[\"Outcome\"].copy()\n",
    "x = dataset.drop(\"Outcome\", axis=1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler as Scaler\n",
    "\n",
    "scaler = Scaler()\n",
    "scaler.fit(x)\n",
    "train_set_scaled = scaler.transform(x)\n",
    "\n",
    "datafram = pd.DataFrame(data=train_set_scaled)\n",
    "\n",
    "\n",
    "#datafram.to_csv(\"diabetes_impute_scaling_std.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(\n",
    "    dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set_labels = train_set[\"Outcome\"].copy()\n",
    "train_set = train_set.drop(\"Outcome\", axis=1)\n",
    "\n",
    "test_set_labels = test_set[\"Outcome\"].copy()\n",
    "test_set = test_set.drop(\"Outcome\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nazmus Sakib\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.311490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144586</td>\n",
       "      <td>0.121688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.479127</td>\n",
       "      <td>0.610304</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.121688</td>\n",
       "      <td>0.343081</td>\n",
       "      <td>0.514091</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.259578</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>0.351525</td>\n",
       "      <td>0.245944</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772492</td>\n",
       "      <td>0.298548</td>\n",
       "      <td>0.144586</td>\n",
       "      <td>0.121688</td>\n",
       "      <td>0.236691</td>\n",
       "      <td>0.075149</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.610842</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.647054</td>\n",
       "      <td>0.068318</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.117647  0.311490  0.000000  0.144586  0.121688  0.000000  0.096499   \n",
       "1  0.529412  0.479127  0.610304  0.290909  0.121688  0.343081  0.514091   \n",
       "2  0.058824  0.640777  0.259578  0.200000  0.082933  0.351525  0.245944   \n",
       "3  0.000000  0.772492  0.298548  0.144586  0.121688  0.236691  0.075149   \n",
       "4  0.352941  0.610842  0.590820  0.527273  0.427885  0.647054  0.068318   \n",
       "\n",
       "          7  \n",
       "0  0.000000  \n",
       "1  0.483333  \n",
       "2  0.016667  \n",
       "3  0.733333  \n",
       "4  0.416667  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler as Scaler\n",
    "\n",
    "scaler = Scaler()\n",
    "scaler.fit(train_set)\n",
    "train_set_scaled = scaler.transform(train_set)\n",
    "test_set_scaled = scaler.transform(test_set)\n",
    "\n",
    "df = pd.DataFrame(data=train_set_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"diabetes_impute_scaling.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_impute_scaling_std.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 11s 14ms/step - loss: 0.4750 - acc: 0.7786\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4802 - acc: 0.7656\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4663 - acc: 0.7812\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4707 - acc: 0.7865\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4647 - acc: 0.7917\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 412us/step - loss: 0.4625 - acc: 0.7721\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4669 - acc: 0.7760\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4746 - acc: 0.7630\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4720 - acc: 0.7760\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4681 - acc: 0.7839\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4696 - acc: 0.7760\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4635 - acc: 0.7891\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4604 - acc: 0.7852\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4693 - acc: 0.7760\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4666 - acc: 0.7747\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4632 - acc: 0.7812\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4616 - acc: 0.7760\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4594 - acc: 0.7839\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4600 - acc: 0.7760\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4667 - acc: 0.7760\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4590 - acc: 0.7904\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4601 - acc: 0.7760\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4526 - acc: 0.7878 0s - loss: 0.4266 - acc: 0.78\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4550 - acc: 0.7865\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4554 - acc: 0.7852\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4548 - acc: 0.7904\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4584 - acc: 0.7995\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4635 - acc: 0.7734\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4603 - acc: 0.7747\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4629 - acc: 0.7773\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4558 - acc: 0.7852\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4605 - acc: 0.7930\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4547 - acc: 0.7773\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4526 - acc: 0.7734\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4659 - acc: 0.7721\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4627 - acc: 0.7747\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4545 - acc: 0.7839\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4606 - acc: 0.7786\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4542 - acc: 0.7747\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4502 - acc: 0.7943\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4518 - acc: 0.7812\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4541 - acc: 0.7826\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4496 - acc: 0.7891\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4485 - acc: 0.7760\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4521 - acc: 0.7773\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4522 - acc: 0.7943\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4487 - acc: 0.7878\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4554 - acc: 0.7721\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4547 - acc: 0.7799\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4573 - acc: 0.7786\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4501 - acc: 0.7839\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4454 - acc: 0.7839\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4523 - acc: 0.7878\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4428 - acc: 0.7839\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4532 - acc: 0.7682\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4475 - acc: 0.7891\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4480 - acc: 0.7773\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4436 - acc: 0.7878\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4529 - acc: 0.7839\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4525 - acc: 0.7878\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4485 - acc: 0.7786\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4439 - acc: 0.7826\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4494 - acc: 0.7760\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4520 - acc: 0.7786\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4461 - acc: 0.7786\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4549 - acc: 0.7865\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4392 - acc: 0.7865\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4470 - acc: 0.7904\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4398 - acc: 0.7839\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4487 - acc: 0.7826\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4449 - acc: 0.7786\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4422 - acc: 0.7852\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4429 - acc: 0.7917\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4373 - acc: 0.7930\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4474 - acc: 0.7878\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4465 - acc: 0.7826\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4559 - acc: 0.7760\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4503 - acc: 0.7943\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4410 - acc: 0.7799\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4492 - acc: 0.7891\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4373 - acc: 0.7839\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4454 - acc: 0.7812\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4409 - acc: 0.7656\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4406 - acc: 0.7773\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4447 - acc: 0.7812\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4431 - acc: 0.7826\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4442 - acc: 0.7799\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4338 - acc: 0.7956\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4389 - acc: 0.7812\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4427 - acc: 0.7773\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4433 - acc: 0.7839\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4404 - acc: 0.7799\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4365 - acc: 0.7943\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4345 - acc: 0.7878\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4395 - acc: 0.7878\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4487 - acc: 0.7826\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4570 - acc: 0.7839\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4416 - acc: 0.7943\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4372 - acc: 0.7995\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4432 - acc: 0.7799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b878c7f5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-27-dcb943b3caa8>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-27-dcb943b3caa8>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    k_features=8,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "feature_selector = SequentialFeatureSelector(Sequential()),\n",
    "           k_features=8,\n",
    "           forward=False,\n",
    "           verbose=2,\n",
    "           scoring='roc_auc',\n",
    "           cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## impute&scaling PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32848414  0.04767619]\n",
      " [-0.22643479 -0.10992424]\n",
      " [ 0.23699816  0.07104916]\n",
      " ...\n",
      " [-0.00726968 -0.08620371]\n",
      " [ 0.02014254 -0.02871416]\n",
      " [-0.27715052 -0.02236748]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy\n",
    "start = time.time()\n",
    "dataset = numpy.loadtxt(\"diabetes_impute_scaling_std.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.6181 - acc: 0.6549\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5434 - acc: 0.7148\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5166 - acc: 0.7448\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5105 - acc: 0.7435\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5074 - acc: 0.7539\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5067 - acc: 0.7448\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5059 - acc: 0.7552\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5045 - acc: 0.7552\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5036 - acc: 0.7526\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5029 - acc: 0.7513\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5022 - acc: 0.7474\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5020 - acc: 0.7591\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5014 - acc: 0.7591\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5013 - acc: 0.7578\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5011 - acc: 0.7500\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5009 - acc: 0.7617\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5010 - acc: 0.7539\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4998 - acc: 0.7630\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4985 - acc: 0.7539\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5002 - acc: 0.7578\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.4994 - acc: 0.7526\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4994 - acc: 0.7565\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4992 - acc: 0.7565\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4980 - acc: 0.7552\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4998 - acc: 0.7513\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4976 - acc: 0.7617\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4985 - acc: 0.7578\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4983 - acc: 0.7526\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4980 - acc: 0.7591\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4976 - acc: 0.7578\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4974 - acc: 0.7565\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4974 - acc: 0.7604\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4971 - acc: 0.7539\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4975 - acc: 0.7578\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4970 - acc: 0.7500\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4979 - acc: 0.7604\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4974 - acc: 0.7591\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4968 - acc: 0.7578\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4992 - acc: 0.7578\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4970 - acc: 0.7565\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4976 - acc: 0.7578\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4965 - acc: 0.7604\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4974 - acc: 0.7565\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4970 - acc: 0.7643\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4975 - acc: 0.7526\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4959 - acc: 0.7552\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4977 - acc: 0.7565\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4974 - acc: 0.7565\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4952 - acc: 0.7578\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4978 - acc: 0.7552\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4965 - acc: 0.7526\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4959 - acc: 0.7565\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4938 - acc: 0.7578\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4972 - acc: 0.7539\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4964 - acc: 0.7578\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4967 - acc: 0.7565\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4965 - acc: 0.7526\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4964 - acc: 0.7565\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4962 - acc: 0.7591\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4963 - acc: 0.7578\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4962 - acc: 0.7552\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4966 - acc: 0.7565\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4974 - acc: 0.7539\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4945 - acc: 0.7552\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4971 - acc: 0.7552\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4967 - acc: 0.7565\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4959 - acc: 0.7578\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 211us/step - loss: 0.4947 - acc: 0.7578\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4957 - acc: 0.7539\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4972 - acc: 0.7461\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4962 - acc: 0.7565\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4950 - acc: 0.7552\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4955 - acc: 0.7591\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4965 - acc: 0.7565\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4960 - acc: 0.7604\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4965 - acc: 0.7539\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4955 - acc: 0.7565\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4951 - acc: 0.7565\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4950 - acc: 0.7552\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4969 - acc: 0.7565\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4953 - acc: 0.7578\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4953 - acc: 0.7552\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4949 - acc: 0.7578\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4952 - acc: 0.7617\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4952 - acc: 0.7552\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4954 - acc: 0.7526\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4957 - acc: 0.7513\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4955 - acc: 0.7591\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4943 - acc: 0.7617\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4950 - acc: 0.7565\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4954 - acc: 0.7604\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4942 - acc: 0.7565\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4969 - acc: 0.7487\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4956 - acc: 0.7565\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4947 - acc: 0.7617\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4964 - acc: 0.7617\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4945 - acc: 0.7591\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4963 - acc: 0.7565\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4948 - acc: 0.7643\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4946 - acc: 0.7539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea9d489c18>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(train_set, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 346us/step\n",
      "\n",
      "acc: 79.1667%\n",
      "18.98348331451416\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## impute & normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nazmus Sakib\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "start = time.time()\n",
    "median_bmi = dataset['BMI'].std()\n",
    "dataset['BMI'] = dataset['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)\n",
    "\n",
    "median_bloodp = dataset['BloodPressure'].std()\n",
    "dataset['BloodPressure'] = dataset['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)\n",
    "\n",
    "median_plglcconc = dataset['Glucose'].std()\n",
    "dataset['Glucose'] = dataset['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)\n",
    "\n",
    "median_skinthick = dataset['SkinThickness'].std()\n",
    "dataset['SkinThickness'] = dataset['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)\n",
    "\n",
    "median_Insulin = dataset['Insulin'].std()\n",
    "dataset['Insulin'] = dataset['Insulin'].replace(\n",
    "    to_replace=0, value=median_Insulin)\n",
    "\n",
    "median_DiabetesPedigreeFunction = dataset['DiabetesPedigreeFunction'].std()\n",
    "dataset['DiabetesPedigreeFunction'] = dataset['DiabetesPedigreeFunction'].replace(\n",
    "    to_replace=0, value=median_DiabetesPedigreeFunction)\n",
    "\n",
    "median_Age = dataset['Age'].std()\n",
    "dataset['Age'] = dataset['Age'].replace(\n",
    "    to_replace=0, value=median_Age)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler as Normalizer\n",
    "\n",
    "scaler = Scaler()\n",
    "scaler.fit(x)\n",
    "train_set_scaled = scaler.transform(x)\n",
    "\n",
    "datafram = pd.DataFrame(data=train_set_scaled)\n",
    "#datafram.to_csv(\"diabetes_impute_normalization_std.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(\n",
    "    dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set_labels = train_set[\"Outcome\"].copy()\n",
    "train_set = train_set.drop(\"Outcome\", axis=1)\n",
    "\n",
    "test_set_labels = test_set[\"Outcome\"].copy()\n",
    "test_set = test_set.drop(\"Outcome\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013648</td>\n",
       "      <td>0.573228</td>\n",
       "      <td>0.132087</td>\n",
       "      <td>0.108860</td>\n",
       "      <td>0.786441</td>\n",
       "      <td>0.053803</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.143307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047106</td>\n",
       "      <td>0.586210</td>\n",
       "      <td>0.429190</td>\n",
       "      <td>0.125616</td>\n",
       "      <td>0.603189</td>\n",
       "      <td>0.147599</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>0.261701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.802569</td>\n",
       "      <td>0.265598</td>\n",
       "      <td>0.109704</td>\n",
       "      <td>0.479232</td>\n",
       "      <td>0.165710</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.127025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745328</td>\n",
       "      <td>0.231468</td>\n",
       "      <td>0.073849</td>\n",
       "      <td>0.533507</td>\n",
       "      <td>0.101383</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.300909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014686</td>\n",
       "      <td>0.327991</td>\n",
       "      <td>0.195815</td>\n",
       "      <td>0.090565</td>\n",
       "      <td>0.905646</td>\n",
       "      <td>0.113083</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.112594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.013648  0.573228  0.132087  0.108860  0.786441  0.053803  0.002075   \n",
       "1  0.047106  0.586210  0.429190  0.125616  0.603189  0.147599  0.006710   \n",
       "2  0.005774  0.802569  0.265598  0.109704  0.479232  0.165710  0.003776   \n",
       "3  0.000000  0.745328  0.231468  0.073849  0.533507  0.101383  0.001176   \n",
       "4  0.014686  0.327991  0.195815  0.090565  0.905646  0.113083  0.000583   \n",
       "\n",
       "          7  \n",
       "0  0.143307  \n",
       "1  0.261701  \n",
       "2  0.127025  \n",
       "3  0.300909  \n",
       "4  0.112594  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer()\n",
    "scaler.fit(train_set)\n",
    "train_set_scaled = scaler.transform(train_set)\n",
    "test_set_scaled = scaler.transform(test_set)\n",
    "\n",
    "df = pd.DataFrame(data=train_set_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"diabetes_impute_normalizer.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_impute_normalization_std.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6801 - acc: 0.5977\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6401 - acc: 0.6510\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6115 - acc: 0.6510\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5931 - acc: 0.6510\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5611 - acc: 0.7214\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5323 - acc: 0.7448\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5094 - acc: 0.7591\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4997 - acc: 0.7591\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4911 - acc: 0.7604\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4845 - acc: 0.7604\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4786 - acc: 0.7734\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4772 - acc: 0.7721\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4730 - acc: 0.7682\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4692 - acc: 0.7695\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4665 - acc: 0.7760\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4649 - acc: 0.7695\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4630 - acc: 0.7747\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4613 - acc: 0.7682\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4610 - acc: 0.7760\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.4570 - acc: 0.7760\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4597 - acc: 0.7799\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4544 - acc: 0.7708\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4534 - acc: 0.7878\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4547 - acc: 0.7812\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4548 - acc: 0.7747\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4532 - acc: 0.7839\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4500 - acc: 0.7826\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4513 - acc: 0.7852\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4525 - acc: 0.7773\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4524 - acc: 0.7891\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4496 - acc: 0.7878\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4495 - acc: 0.7878\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4478 - acc: 0.7839\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4475 - acc: 0.7839\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4474 - acc: 0.7839\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4466 - acc: 0.7878\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4480 - acc: 0.7904\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4463 - acc: 0.7891\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4444 - acc: 0.7943\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4464 - acc: 0.7852\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4420 - acc: 0.7956\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4445 - acc: 0.7917\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4450 - acc: 0.7812\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4424 - acc: 0.7891\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4409 - acc: 0.7982\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4421 - acc: 0.7969\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4429 - acc: 0.7839\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4408 - acc: 0.7917\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4393 - acc: 0.7969\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4420 - acc: 0.7865\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4407 - acc: 0.7969\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4399 - acc: 0.7917\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4425 - acc: 0.7891\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4397 - acc: 0.7982\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4389 - acc: 0.7865\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4388 - acc: 0.7956\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4399 - acc: 0.7904\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4401 - acc: 0.7930\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4385 - acc: 0.7930\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4405 - acc: 0.7995\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4354 - acc: 0.7969\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4391 - acc: 0.7891\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4409 - acc: 0.7878\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4353 - acc: 0.7917\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4367 - acc: 0.7943\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.4405 - acc: 0.797 - 0s 142us/step - loss: 0.4382 - acc: 0.7904\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4358 - acc: 0.7969\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4374 - acc: 0.7917\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4369 - acc: 0.7956\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4370 - acc: 0.7891\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4359 - acc: 0.7930\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4395 - acc: 0.8047\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4333 - acc: 0.7943\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4345 - acc: 0.7865\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4338 - acc: 0.7943\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4374 - acc: 0.7904\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4341 - acc: 0.7995\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4323 - acc: 0.8060\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4341 - acc: 0.7956\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4326 - acc: 0.8008\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4338 - acc: 0.8021\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4330 - acc: 0.7930\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4342 - acc: 0.7943\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4335 - acc: 0.8034\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4313 - acc: 0.7930\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4304 - acc: 0.7943\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4315 - acc: 0.7852\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4307 - acc: 0.7930\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4324 - acc: 0.7930\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4302 - acc: 0.7995\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4322 - acc: 0.7930\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4307 - acc: 0.8034\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 148us/step - loss: 0.4304 - acc: 0.7943\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4288 - acc: 0.8047\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4304 - acc: 0.8060\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4277 - acc: 0.7995\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4274 - acc: 0.7995\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4266 - acc: 0.8008\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4318 - acc: 0.7891\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4293 - acc: 0.7943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x254e3c10828>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 387us/step\n",
      "\n",
      "acc: 80.4688%\n",
      "22.591076612472534\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## impute&normalization PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_impute_normalization_std.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32848414  0.04767619]\n",
      " [-0.22643479 -0.10992424]\n",
      " [ 0.23699816  0.07104916]\n",
      " ...\n",
      " [-0.00726968 -0.08620371]\n",
      " [ 0.02014254 -0.02871416]\n",
      " [-0.27715052 -0.02236748]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_16_input to have shape (8,) but got array with shape (7,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2639a519e47c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Nadam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_16_input to have shape (8,) but got array with shape (7,)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 365us/step\n",
      "\n",
      "acc: 79.8177%\n",
      "20.445217847824097\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without bloodpressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33156191  0.07402733]\n",
      " [-0.22132405 -0.12891123]\n",
      " [ 0.26745423  0.12850989]\n",
      " ...\n",
      " [-0.00732415 -0.08887756]\n",
      " [ 0.04826286 -0.00317944]\n",
      " [-0.28788377 -0.05417924]]\n",
      "Epoch 1/100\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.6235 - acc: 0.7109\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5285 - acc: 0.7396\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4969 - acc: 0.7513\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4901 - acc: 0.7539\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4869 - acc: 0.7565\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4857 - acc: 0.7591\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4846 - acc: 0.7682\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4837 - acc: 0.7656\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4831 - acc: 0.7630\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4821 - acc: 0.7643\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4814 - acc: 0.7578\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4820 - acc: 0.7565\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4794 - acc: 0.7604\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4793 - acc: 0.7669\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4803 - acc: 0.7630\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4789 - acc: 0.7682\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4791 - acc: 0.7617\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4787 - acc: 0.7630\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4775 - acc: 0.7695\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4786 - acc: 0.7682\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4774 - acc: 0.7682\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4782 - acc: 0.7630\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4778 - acc: 0.7643\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4765 - acc: 0.7630\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4774 - acc: 0.7630\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4778 - acc: 0.7643\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4771 - acc: 0.7695\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4763 - acc: 0.7656\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4772 - acc: 0.7643\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4771 - acc: 0.7604\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4761 - acc: 0.7617\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4775 - acc: 0.7643\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4768 - acc: 0.7656\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4763 - acc: 0.7682\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4779 - acc: 0.7630\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4751 - acc: 0.7630\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4775 - acc: 0.7617\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4762 - acc: 0.7591\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4770 - acc: 0.7643\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4771 - acc: 0.7617\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4764 - acc: 0.7643\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4765 - acc: 0.7604\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4767 - acc: 0.7617\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4766 - acc: 0.7630\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4763 - acc: 0.7565\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.4771 - acc: 0.7656\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4765 - acc: 0.7682\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4760 - acc: 0.7643\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4761 - acc: 0.7591\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4764 - acc: 0.7656\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4770 - acc: 0.7682\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4764 - acc: 0.7643\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4768 - acc: 0.7656\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4765 - acc: 0.7578\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4753 - acc: 0.7630 0s - loss: 0.4455 - acc: 0.79\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4764 - acc: 0.7617\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.4765 - acc: 0.7604\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.4762 - acc: 0.7643\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4764 - acc: 0.7604\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4758 - acc: 0.7643\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4762 - acc: 0.7630\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4758 - acc: 0.7630\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4760 - acc: 0.7617\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4758 - acc: 0.7617\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4762 - acc: 0.7578\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4765 - acc: 0.7630\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4777 - acc: 0.7617\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4759 - acc: 0.7656\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4754 - acc: 0.7578\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4745 - acc: 0.7630\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4782 - acc: 0.7526\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4763 - acc: 0.7552\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4757 - acc: 0.7604\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4748 - acc: 0.7630\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4749 - acc: 0.7591\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4771 - acc: 0.7630\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4769 - acc: 0.7682\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4764 - acc: 0.7617\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4753 - acc: 0.7643\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4766 - acc: 0.7552\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 171us/step - loss: 0.4768 - acc: 0.7552\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4762 - acc: 0.7630\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4761 - acc: 0.7604\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.4753 - acc: 0.7617\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4759 - acc: 0.7643\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4753 - acc: 0.7643\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4755 - acc: 0.7565\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4776 - acc: 0.7682\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.4750 - acc: 0.7617\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4752 - acc: 0.7630\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4750 - acc: 0.7630\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4752 - acc: 0.7643\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4755 - acc: 0.7604\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.4758 - acc: 0.7630\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4761 - acc: 0.7617\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4759 - acc: 0.7656\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4755 - acc: 0.7604\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4750 - acc: 0.7630\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4752 - acc: 0.7669\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4750 - acc: 0.7630\n",
      "768/768 [==============================] - 0s 551us/step\n",
      "\n",
      "acc: 76.5625%\n"
     ]
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_std_impute_scaling_bloodpressure.txt\", delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:7]\n",
    "Y = dataset[:,7]\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(train_set, Y, epochs=100, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(train_set, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without SkinThickness and bloodpressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32871259  0.05586229]\n",
      " [-0.22152933 -0.14204061]\n",
      " [ 0.2699094   0.17365834]\n",
      " ...\n",
      " [-0.0059357  -0.07882997]\n",
      " [ 0.05111037  0.03032706]\n",
      " [-0.28920874 -0.07454613]]\n",
      "Epoch 1/100\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6796 - acc: 0.6966\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 219us/step - loss: 0.6332 - acc: 0.7435\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5645 - acc: 0.7487\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5180 - acc: 0.7513\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5036 - acc: 0.7500\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4983 - acc: 0.7552\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4979 - acc: 0.7552\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4961 - acc: 0.7539\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4957 - acc: 0.7500\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4956 - acc: 0.7500\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4945 - acc: 0.7513\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4930 - acc: 0.7539\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4929 - acc: 0.7539\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4942 - acc: 0.7500\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4924 - acc: 0.7513\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4921 - acc: 0.7565\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4918 - acc: 0.7474\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4917 - acc: 0.7448\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4904 - acc: 0.7513\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4893 - acc: 0.7500\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4882 - acc: 0.7565\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4894 - acc: 0.7539\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4879 - acc: 0.7487\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4872 - acc: 0.7526\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4869 - acc: 0.7435\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4869 - acc: 0.7461\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4858 - acc: 0.7526\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4858 - acc: 0.7435\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4851 - acc: 0.7474\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4849 - acc: 0.7474\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4845 - acc: 0.7552\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4841 - acc: 0.7474\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4837 - acc: 0.7552\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4835 - acc: 0.7500\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4822 - acc: 0.7591\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4837 - acc: 0.7539\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4826 - acc: 0.7513\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4816 - acc: 0.7487\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4845 - acc: 0.7500\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4827 - acc: 0.7552\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4820 - acc: 0.7526\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4823 - acc: 0.7565\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4825 - acc: 0.7552\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4822 - acc: 0.7526\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4819 - acc: 0.7565\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4831 - acc: 0.7565\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4817 - acc: 0.7526\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4813 - acc: 0.7526\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4812 - acc: 0.7539\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4818 - acc: 0.7539\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4810 - acc: 0.7552\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4818 - acc: 0.7552\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4806 - acc: 0.7604\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4809 - acc: 0.7552\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4805 - acc: 0.7552\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4811 - acc: 0.7487\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4813 - acc: 0.7604\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4817 - acc: 0.7539\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4801 - acc: 0.7526\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4800 - acc: 0.7539\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4810 - acc: 0.7500\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4805 - acc: 0.7500\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4813 - acc: 0.7591\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4791 - acc: 0.7552\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4795 - acc: 0.7591\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4823 - acc: 0.7578\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4799 - acc: 0.7604 0s - loss: 0.4785 - acc: 0.76\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4798 - acc: 0.7526\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4797 - acc: 0.7500\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4800 - acc: 0.7526\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4802 - acc: 0.7565\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4790 - acc: 0.7604\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4802 - acc: 0.7591\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4794 - acc: 0.7591\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4795 - acc: 0.7500\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4792 - acc: 0.7552\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4798 - acc: 0.7552\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4808 - acc: 0.7539\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4794 - acc: 0.7487\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4793 - acc: 0.7565\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 171us/step - loss: 0.4797 - acc: 0.7539\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4795 - acc: 0.7539\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4801 - acc: 0.7513\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4794 - acc: 0.7565\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4796 - acc: 0.7552\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4789 - acc: 0.7591\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4792 - acc: 0.7539\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4792 - acc: 0.7565\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4792 - acc: 0.7591\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4794 - acc: 0.7565\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4791 - acc: 0.7565\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4789 - acc: 0.7552\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4795 - acc: 0.7578\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.4804 - acc: 0.7578\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4790 - acc: 0.7539\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4786 - acc: 0.7630\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4788 - acc: 0.7539\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4792 - acc: 0.7552\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4795 - acc: 0.7565\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4791 - acc: 0.7578\n",
      "768/768 [==============================] - 0s 421us/step\n",
      "\n",
      "acc: 75.5208%\n"
     ]
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_std_impute_scaling_bloodpressure_skinness.txt\", delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:6]\n",
    "Y = dataset[:,6]\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(train_set, Y, epochs=100, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(train_set, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without SkinThickness and bloodpressure and insuilin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33047851  0.08209394]\n",
      " [-0.21675473 -0.14975132]\n",
      " [ 0.26842772  0.19856396]\n",
      " ...\n",
      " [-0.00193256 -0.07505384]\n",
      " [ 0.05280656  0.04378335]\n",
      " [-0.28633215 -0.08402202]]\n",
      "Epoch 1/100\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6506 - acc: 0.6263\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.5830 - acc: 0.657 - 0s 241us/step - loss: 0.5777 - acc: 0.6576\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5312 - acc: 0.7435\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5045 - acc: 0.7526\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4952 - acc: 0.7513\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4895 - acc: 0.7487\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4865 - acc: 0.7565\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4853 - acc: 0.7526\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4839 - acc: 0.7539\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4836 - acc: 0.7578\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4826 - acc: 0.7539\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4834 - acc: 0.7565\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4811 - acc: 0.7565\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4820 - acc: 0.7552\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4816 - acc: 0.7643\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4810 - acc: 0.7591\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4813 - acc: 0.7578\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4800 - acc: 0.7630\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4800 - acc: 0.7591\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 211us/step - loss: 0.4799 - acc: 0.7552\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4795 - acc: 0.7630\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4800 - acc: 0.7669\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4788 - acc: 0.7578\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4790 - acc: 0.7604\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4792 - acc: 0.7578\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4783 - acc: 0.7643\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4785 - acc: 0.7539\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4787 - acc: 0.7604\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4781 - acc: 0.7591\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4778 - acc: 0.7617\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4776 - acc: 0.7617\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4768 - acc: 0.7591\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4782 - acc: 0.7591\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4767 - acc: 0.7617\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4798 - acc: 0.7708\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4773 - acc: 0.7565\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4777 - acc: 0.7578\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4762 - acc: 0.7578\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4769 - acc: 0.7578\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4767 - acc: 0.7604\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4769 - acc: 0.7591\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4764 - acc: 0.7604\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4769 - acc: 0.7578\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4772 - acc: 0.7604\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4764 - acc: 0.7630\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4777 - acc: 0.7565\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4774 - acc: 0.7591\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4769 - acc: 0.7565\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4763 - acc: 0.7591\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4770 - acc: 0.7591\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4764 - acc: 0.7630\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4764 - acc: 0.7630\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4771 - acc: 0.7591\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4763 - acc: 0.7591\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4768 - acc: 0.7578\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4765 - acc: 0.7604\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4764 - acc: 0.7630\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4751 - acc: 0.7630\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4766 - acc: 0.7604\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4762 - acc: 0.7617\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4765 - acc: 0.7630\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4768 - acc: 0.7604\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4758 - acc: 0.7565\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4760 - acc: 0.7578\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4766 - acc: 0.7604\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4763 - acc: 0.7630\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4759 - acc: 0.7630\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4756 - acc: 0.7591\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4762 - acc: 0.7539\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4768 - acc: 0.7552\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4756 - acc: 0.7604\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4761 - acc: 0.7630\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4747 - acc: 0.7630\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4769 - acc: 0.7591\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4760 - acc: 0.7565\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4763 - acc: 0.7552\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4761 - acc: 0.7578\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4758 - acc: 0.7604\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4763 - acc: 0.7669\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4758 - acc: 0.7604\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 212us/step - loss: 0.4767 - acc: 0.7578\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4756 - acc: 0.7591\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4761 - acc: 0.7552\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4758 - acc: 0.7591\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4760 - acc: 0.7617\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4762 - acc: 0.7630\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4754 - acc: 0.7578\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4761 - acc: 0.7643\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4764 - acc: 0.7565\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4754 - acc: 0.7565\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4764 - acc: 0.7656\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4767 - acc: 0.7578\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4765 - acc: 0.7591\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4762 - acc: 0.7617\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4754 - acc: 0.7669\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4752 - acc: 0.7565\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4747 - acc: 0.7591\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4758 - acc: 0.7630\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4755 - acc: 0.7630\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4758 - acc: 0.7539\n",
      "768/768 [==============================] - 0s 351us/step\n",
      "\n",
      "acc: 76.0417%\n"
     ]
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_std_impute_scaling_bloodpressure_skinness_insulin.txt\", delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:5]\n",
    "Y = dataset[:,5]\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(train_set, Y, epochs=100, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(train_set, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without SkinThickness and bloodpressure and insuilin and diabetesFuncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32810897  0.07070331]\n",
      " [-0.2144913  -0.14406483]\n",
      " [ 0.26515485  0.19245054]\n",
      " ...\n",
      " [ 0.00164768 -0.0477599 ]\n",
      " [ 0.05427564  0.06053743]\n",
      " [-0.2839358  -0.07253812]]\n",
      "Epoch 1/100\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6754 - acc: 0.6445\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.6028 - acc: 0.6549\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5336 - acc: 0.7279\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5047 - acc: 0.7500\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4960 - acc: 0.7474\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4925 - acc: 0.7474\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4924 - acc: 0.7500\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4897 - acc: 0.7500\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4897 - acc: 0.7448\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4885 - acc: 0.7578\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4885 - acc: 0.7513\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4884 - acc: 0.7526\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4880 - acc: 0.7500\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.4860 - acc: 0.7474\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4873 - acc: 0.7461\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4864 - acc: 0.7487\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4874 - acc: 0.7474\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4871 - acc: 0.7474\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4873 - acc: 0.7513\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4868 - acc: 0.7539\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4865 - acc: 0.7591\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4860 - acc: 0.7487\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4851 - acc: 0.7461\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4853 - acc: 0.7474\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4855 - acc: 0.7409\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4854 - acc: 0.7565\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4852 - acc: 0.7487\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4850 - acc: 0.7500\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4831 - acc: 0.7695\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4823 - acc: 0.7500\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4841 - acc: 0.7552\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4848 - acc: 0.7500\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4841 - acc: 0.7474\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4828 - acc: 0.7539\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4841 - acc: 0.7500\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.4841 - acc: 0.7552\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4827 - acc: 0.7500\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4831 - acc: 0.7513\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4837 - acc: 0.7487\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4840 - acc: 0.7474\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4826 - acc: 0.7604\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4816 - acc: 0.7539\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4830 - acc: 0.7539\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4826 - acc: 0.7526\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4823 - acc: 0.7513\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4827 - acc: 0.7526\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4814 - acc: 0.7526\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4827 - acc: 0.7500\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4809 - acc: 0.7513\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4826 - acc: 0.7526\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4817 - acc: 0.7526\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4820 - acc: 0.7539\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4819 - acc: 0.7500\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4815 - acc: 0.7526\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4827 - acc: 0.7578\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4815 - acc: 0.7552\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4811 - acc: 0.7604\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4830 - acc: 0.7565\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4812 - acc: 0.7539\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4813 - acc: 0.7591\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4809 - acc: 0.7539\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4818 - acc: 0.7604\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4812 - acc: 0.7604\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.4802 - acc: 0.7513\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4810 - acc: 0.7552\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4819 - acc: 0.7565\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.4807 - acc: 0.7591 0s - loss: 0.4620 - acc: 0.768 - ETA: 0s - loss: 0.4833 - acc: 0.757\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.4809 - acc: 0.7565\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4811 - acc: 0.7526\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4804 - acc: 0.7578\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4804 - acc: 0.7565\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4808 - acc: 0.7539\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4814 - acc: 0.7552\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.4807 - acc: 0.7552\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4805 - acc: 0.7513\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4801 - acc: 0.7565\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.4802 - acc: 0.7526\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.4809 - acc: 0.7630\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4801 - acc: 0.7487\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4795 - acc: 0.7604\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 220us/step - loss: 0.4801 - acc: 0.7552\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4807 - acc: 0.7578\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4803 - acc: 0.7526\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4789 - acc: 0.7513\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4793 - acc: 0.7487\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4801 - acc: 0.7591\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4794 - acc: 0.7552\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4793 - acc: 0.7552\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4796 - acc: 0.7474\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4796 - acc: 0.7552\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4784 - acc: 0.7617\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4792 - acc: 0.7539\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4801 - acc: 0.7565\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4787 - acc: 0.7617\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4804 - acc: 0.7500\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4787 - acc: 0.7513\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4783 - acc: 0.7578\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4802 - acc: 0.7578\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4786 - acc: 0.7578\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4798 - acc: 0.7565\n",
      "768/768 [==============================] - 0s 392us/step\n",
      "\n",
      "acc: 76.3021%\n"
     ]
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_std_impute_scaling_diabetesprectionfuncation.txt\", delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:4]\n",
    "Y = dataset[:,4]\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(train_set, Y, epochs=100, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(train_set, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without SkinThickness and bloodpressure and insuilin and diabetesFuncation and pregnencis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31638213  0.06700722]\n",
      " [-0.18224975  0.15068438]\n",
      " [ 0.20809719 -0.23127169]\n",
      " ...\n",
      " [-0.05391107 -0.00850498]\n",
      " [ 0.18478857  0.14136734]\n",
      " [-0.24102587  0.01126602]]\n",
      "Epoch 1/100\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6132 - acc: 0.6628\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5350 - acc: 0.7357\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5009 - acc: 0.7630\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4894 - acc: 0.7617\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4846 - acc: 0.7630\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4823 - acc: 0.7643\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4805 - acc: 0.7734\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4801 - acc: 0.7604\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4788 - acc: 0.7617\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4780 - acc: 0.7630\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4797 - acc: 0.7617\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4771 - acc: 0.7578\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4763 - acc: 0.7630\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4770 - acc: 0.7643\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4759 - acc: 0.7643\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4752 - acc: 0.7682\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4758 - acc: 0.7617\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4758 - acc: 0.7656\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4761 - acc: 0.7721\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4754 - acc: 0.7630\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4749 - acc: 0.7669\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4744 - acc: 0.7656\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4757 - acc: 0.7708\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.4734 - acc: 0.7656\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4735 - acc: 0.7708\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.4749 - acc: 0.7695\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 237us/step - loss: 0.4742 - acc: 0.7630\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4729 - acc: 0.7630\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.4729 - acc: 0.7643\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4740 - acc: 0.7682\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.4731 - acc: 0.7695\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.4722 - acc: 0.7656\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.4724 - acc: 0.7630\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.4722 - acc: 0.7682\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4727 - acc: 0.7656\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 351us/step - loss: 0.4733 - acc: 0.7669\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4725 - acc: 0.7643\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4739 - acc: 0.7747\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4721 - acc: 0.7656\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4722 - acc: 0.7656\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4718 - acc: 0.7656\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4741 - acc: 0.7669\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4722 - acc: 0.7656\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4723 - acc: 0.7578\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4719 - acc: 0.7643\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4719 - acc: 0.7708\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.4721 - acc: 0.7695\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4723 - acc: 0.7630\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4719 - acc: 0.7669\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4715 - acc: 0.7578\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4716 - acc: 0.7708\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4724 - acc: 0.7578\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4717 - acc: 0.7656\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4713 - acc: 0.7682\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4717 - acc: 0.7604\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4711 - acc: 0.7682\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4713 - acc: 0.7643\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4720 - acc: 0.7630\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4718 - acc: 0.7669\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4719 - acc: 0.7643\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4711 - acc: 0.7682\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4703 - acc: 0.7708\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4712 - acc: 0.7617\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4725 - acc: 0.7708\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4717 - acc: 0.7682\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4711 - acc: 0.7656\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4708 - acc: 0.7682\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4712 - acc: 0.7656\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4706 - acc: 0.7747\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4712 - acc: 0.7695\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4708 - acc: 0.7682\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4707 - acc: 0.7604\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4724 - acc: 0.7695\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4713 - acc: 0.7643\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4696 - acc: 0.7721\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4717 - acc: 0.7682\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4710 - acc: 0.7669\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4710 - acc: 0.7695\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4712 - acc: 0.7630\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4713 - acc: 0.7734\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4700 - acc: 0.7669\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 261us/step - loss: 0.4704 - acc: 0.7669\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4706 - acc: 0.7643\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.4707 - acc: 0.7708\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4721 - acc: 0.7656\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4700 - acc: 0.7708\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4712 - acc: 0.7643\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4717 - acc: 0.7669\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4692 - acc: 0.7669\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4718 - acc: 0.7695\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4707 - acc: 0.7630\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4710 - acc: 0.7682\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4709 - acc: 0.7656\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4695 - acc: 0.7669\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4713 - acc: 0.7656\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4703 - acc: 0.7721\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4703 - acc: 0.7630\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4696 - acc: 0.7695\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4702 - acc: 0.7721\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4709 - acc: 0.7591\n",
      "768/768 [==============================] - 0s 423us/step\n",
      "\n",
      "acc: 77.0833%\n"
     ]
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_std_impute_scaling_pregnancies.txt\", delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:3]\n",
    "Y = dataset[:,3]\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(train_set, Y, epochs=100, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(train_set, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without  age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1621273  -0.01685487]\n",
      " [ 0.2327525  -0.03450266]\n",
      " [-0.32012554 -0.23866873]\n",
      " ...\n",
      " [ 0.02614077 -0.09624342]\n",
      " [-0.01966656 -0.04024838]\n",
      " [ 0.17001591  0.01525906]]\n",
      "Epoch 1/100\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.6621 - acc: 0.6172\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5751 - acc: 0.7318\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5212 - acc: 0.7591\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5047 - acc: 0.7643\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5014 - acc: 0.7669\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4990 - acc: 0.7656\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4997 - acc: 0.7617\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4986 - acc: 0.7682\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4987 - acc: 0.7760\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4981 - acc: 0.7617\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4973 - acc: 0.7721\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4976 - acc: 0.7630\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4975 - acc: 0.7617\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4968 - acc: 0.7643\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4960 - acc: 0.7695\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4962 - acc: 0.7734\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4962 - acc: 0.7682\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4961 - acc: 0.7617\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4949 - acc: 0.7643\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4954 - acc: 0.7695\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4954 - acc: 0.7708\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.4942 - acc: 0.7708\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4947 - acc: 0.7734\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4934 - acc: 0.7695\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4933 - acc: 0.7786\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4916 - acc: 0.7643\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4941 - acc: 0.7617\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4919 - acc: 0.7682\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.4921 - acc: 0.7591\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4922 - acc: 0.7630\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.4929 - acc: 0.7695\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4917 - acc: 0.7669\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4922 - acc: 0.7682\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4904 - acc: 0.7630\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4920 - acc: 0.7604\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.4905 - acc: 0.7643\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4903 - acc: 0.7734\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4902 - acc: 0.7539\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4910 - acc: 0.7591\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4907 - acc: 0.7617\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4902 - acc: 0.7643\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.4887 - acc: 0.7630\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4899 - acc: 0.7578\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4889 - acc: 0.7604\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4885 - acc: 0.7695\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4884 - acc: 0.7617\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4883 - acc: 0.7656\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4876 - acc: 0.7682\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4877 - acc: 0.7721\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4875 - acc: 0.7643\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4873 - acc: 0.7682\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4855 - acc: 0.7734\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4876 - acc: 0.7643\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4872 - acc: 0.7669\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4866 - acc: 0.7656\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4871 - acc: 0.7656\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4857 - acc: 0.7591\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4880 - acc: 0.7669\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4863 - acc: 0.7565\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4866 - acc: 0.7682\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4840 - acc: 0.7721\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4869 - acc: 0.7656\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4840 - acc: 0.7656\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4855 - acc: 0.7643\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4860 - acc: 0.7578\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4849 - acc: 0.7682\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4845 - acc: 0.7669\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4840 - acc: 0.7656\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4844 - acc: 0.7708\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4844 - acc: 0.7630\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4830 - acc: 0.7682\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4835 - acc: 0.7630\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4845 - acc: 0.7656\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4830 - acc: 0.7682\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4838 - acc: 0.7760\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4843 - acc: 0.7656\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4833 - acc: 0.7643\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4832 - acc: 0.7695\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.4836 - acc: 0.7656\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.4822 - acc: 0.7565\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4843 - acc: 0.7721\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 180us/step - loss: 0.4816 - acc: 0.7656\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4818 - acc: 0.7643\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4807 - acc: 0.7695\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4821 - acc: 0.7734\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4825 - acc: 0.7669\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4816 - acc: 0.7669\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4817 - acc: 0.7617\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4826 - acc: 0.7591\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4790 - acc: 0.7695\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4827 - acc: 0.7591\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4794 - acc: 0.7669\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4815 - acc: 0.7682\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4821 - acc: 0.7630\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4800 - acc: 0.7695\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4808 - acc: 0.7630\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4824 - acc: 0.7591\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4804 - acc: 0.7656\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4794 - acc: 0.7695\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4822 - acc: 0.7682\n",
      "768/768 [==============================] - 0s 392us/step\n",
      "\n",
      "acc: 77.3438%\n"
     ]
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_std_impute_scaling_age.txt\", delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:2]\n",
    "Y = dataset[:,2]\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(train_set, Y, epochs=100, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(train_set, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16103536]\n",
      " [ 0.21614831]\n",
      " [-0.37058184]\n",
      " [ 0.19220014]\n",
      " [-0.09517789]\n",
      " [ 0.03055   ]\n",
      " [ 0.25805761]\n",
      " [ 0.03653704]\n",
      " [-0.45440043]\n",
      " [-0.02333338]\n",
      " [ 0.06647225]\n",
      " [-0.2807762 ]\n",
      " [-0.10715197]\n",
      " [-0.40650409]\n",
      " [-0.26880212]\n",
      " [ 0.12634268]\n",
      " [ 0.01857591]\n",
      " [ 0.08443338]\n",
      " [ 0.10838155]\n",
      " [ 0.03653704]\n",
      " [-0.02932042]\n",
      " [ 0.13232972]\n",
      " [-0.44841339]\n",
      " [ 0.01258887]\n",
      " [-0.13110014]\n",
      " [-0.02333338]\n",
      " [-0.15504831]\n",
      " [ 0.1443038 ]\n",
      " [-0.14307423]\n",
      " [ 0.02456296]\n",
      " [ 0.07245929]\n",
      " [-0.22090578]\n",
      " [ 0.19818718]\n",
      " [ 0.17423901]\n",
      " [-0.00537226]\n",
      " [ 0.10838155]\n",
      " [-0.10116493]\n",
      " [ 0.11436859]\n",
      " [ 0.1862131 ]\n",
      " [ 0.06048521]\n",
      " [-0.35262071]\n",
      " [-0.07122972]\n",
      " [ 0.09042042]\n",
      " [-0.29873733]\n",
      " [-0.22689282]\n",
      " [-0.35262071]\n",
      " [-0.14906127]\n",
      " [ 0.2999669 ]\n",
      " [ 0.10838155]\n",
      " [ 0.09640746]\n",
      " [ 0.10838155]\n",
      " [ 0.12035563]\n",
      " [ 0.19818718]\n",
      " [-0.32867254]\n",
      " [-0.17300944]\n",
      " [ 0.28799282]\n",
      " [-0.39453   ]\n",
      " [ 0.12634268]\n",
      " [-0.14906127]\n",
      " [ 0.09640746]\n",
      " [ 0.22213535]\n",
      " [-0.07122972]\n",
      " [ 0.46161704]\n",
      " [-0.11912606]\n",
      " [ 0.04252408]\n",
      " [ 0.13232972]\n",
      " [ 0.07245929]\n",
      " [ 0.07245929]\n",
      " [ 0.15627789]\n",
      " [-0.14906127]\n",
      " [ 0.12634268]\n",
      " [-0.10715197]\n",
      " [-0.02932042]\n",
      " [-0.04728155]\n",
      " [ 0.25207056]\n",
      " [ 0.53362549]\n",
      " [ 0.35385028]\n",
      " [ 0.15627789]\n",
      " [-0.05925564]\n",
      " [ 0.05449817]\n",
      " [ 0.04851113]\n",
      " [ 0.28200577]\n",
      " [ 0.22812239]\n",
      " [ 0.12035563]\n",
      " [-0.09517789]\n",
      " [ 0.06647225]\n",
      " [ 0.09042042]\n",
      " [ 0.12634268]\n",
      " [-0.08919085]\n",
      " [ 0.08443338]\n",
      " [ 0.24608352]\n",
      " [-0.0113593 ]\n",
      " [ 0.24009648]\n",
      " [-0.07721676]\n",
      " [-0.1251131 ]\n",
      " [-0.13708719]\n",
      " [ 0.17423901]\n",
      " [ 0.2999669 ]\n",
      " [ 0.16825197]\n",
      " [-0.00537226]\n",
      " [-0.25084099]\n",
      " [-0.17899648]\n",
      " [-0.02333338]\n",
      " [ 0.24009648]\n",
      " [ 0.21614831]\n",
      " [-0.02932042]\n",
      " [ 0.15029084]\n",
      " [-0.13708719]\n",
      " [ 0.22812239]\n",
      " [ 0.15627789]\n",
      " [-0.29873733]\n",
      " [-0.20294465]\n",
      " [ 0.19220014]\n",
      " [ 0.27003169]\n",
      " [-0.23287986]\n",
      " [-0.14906127]\n",
      " [-0.01734634]\n",
      " [ 0.25805761]\n",
      " [ 0.1443038 ]\n",
      " [ 0.13232972]\n",
      " [-0.24485395]\n",
      " [ 0.06048521]\n",
      " [ 0.08443338]\n",
      " [-0.06524268]\n",
      " [ 0.04851113]\n",
      " [ 0.19818718]\n",
      " [ 0.00660183]\n",
      " [ 0.01857591]\n",
      " [ 0.02456296]\n",
      " [ 0.09640746]\n",
      " [-0.31071141]\n",
      " [-0.00537226]\n",
      " [-0.29275029]\n",
      " [ 0.22213535]\n",
      " [ 0.15029084]\n",
      " [-0.02333338]\n",
      " [ 0.12634268]\n",
      " [ 0.16825197]\n",
      " [-0.04728155]\n",
      " [ 0.09640746]\n",
      " [-0.04129451]\n",
      " [ 0.09042042]\n",
      " [ 0.07844634]\n",
      " [ 0.07844634]\n",
      " [-0.19695761]\n",
      " [ 0.11436859]\n",
      " [ 0.38378549]\n",
      " [ 0.09042042]\n",
      " [-0.15504831]\n",
      " [ 0.1862131 ]\n",
      " [-0.08919085]\n",
      " [ 0.04252408]\n",
      " [-0.20893169]\n",
      " [-0.19097057]\n",
      " [-0.40051705]\n",
      " [-0.18498352]\n",
      " [ 0.13232972]\n",
      " [ 0.07245929]\n",
      " [ 0.19818718]\n",
      " [-0.25084099]\n",
      " [-0.17899648]\n",
      " [ 0.11436859]\n",
      " [ 0.04252408]\n",
      " [ 0.12634268]\n",
      " [-0.05925564]\n",
      " [ 0.10239451]\n",
      " [-0.16103536]\n",
      " [ 0.00660183]\n",
      " [ 0.06647225]\n",
      " [ 0.06048521]\n",
      " [ 0.11436859]\n",
      " [-0.07721676]\n",
      " [ 0.20417423]\n",
      " [ 0.25207056]\n",
      " [ 0.27601873]\n",
      " [-0.34663367]\n",
      " [ 0.21614831]\n",
      " [-0.04728155]\n",
      " [-0.13110014]\n",
      " [-0.05326859]\n",
      " [ 0.20417423]\n",
      " [ 0.01258887]\n",
      " [ 0.53362549]\n",
      " [ 0.28799282]\n",
      " [-0.11912606]\n",
      " [-0.4364393 ]\n",
      " [-0.35860775]\n",
      " [-0.04129451]\n",
      " [ 0.07245929]\n",
      " [-0.10715197]\n",
      " [ 0.06048521]\n",
      " [-0.0113593 ]\n",
      " [-0.22689282]\n",
      " [-0.08320381]\n",
      " [ 0.21614831]\n",
      " [-0.22090578]\n",
      " [ 0.09640746]\n",
      " [ 0.08443338]\n",
      " [ 0.07245929]\n",
      " [-0.16103536]\n",
      " [ 0.04851113]\n",
      " [-0.10116493]\n",
      " [ 0.07844634]\n",
      " [ 0.13232972]\n",
      " [ 0.10838155]\n",
      " [ 0.06048521]\n",
      " [-0.44841339]\n",
      " [-0.24485395]\n",
      " [ 0.15029084]\n",
      " [-0.37656888]\n",
      " [ 0.24009648]\n",
      " [-0.15504831]\n",
      " [-0.34663367]\n",
      " [-0.11313902]\n",
      " [ 0.05449817]\n",
      " [-0.17899648]\n",
      " [ 0.07245929]\n",
      " [-0.02333338]\n",
      " [ 0.21614831]\n",
      " [ 0.05449817]\n",
      " [-0.33465958]\n",
      " [-0.22090578]\n",
      " [ 0.01258887]\n",
      " [-0.1251131 ]\n",
      " [ 0.12634268]\n",
      " [ 0.20417423]\n",
      " [ 0.12035563]\n",
      " [-0.24485395]\n",
      " [-0.45440043]\n",
      " [ 0.02456296]\n",
      " [-0.1251131 ]\n",
      " [-0.07721676]\n",
      " [ 0.25207056]\n",
      " [-0.00537226]\n",
      " [ 0.28200577]\n",
      " [-0.29873733]\n",
      " [-0.35860775]\n",
      " [-0.34663367]\n",
      " [-0.25682803]\n",
      " [ 0.10239451]\n",
      " [ 0.18022606]\n",
      " [ 0.18022606]\n",
      " [-0.10715197]\n",
      " [ 0.01258887]\n",
      " [-0.14906127]\n",
      " [-0.37656888]\n",
      " [-0.00537226]\n",
      " [-0.26281507]\n",
      " [-0.01734634]\n",
      " [ 0.06048521]\n",
      " [ 0.09042042]\n",
      " [-0.04728155]\n",
      " [ 0.1862131 ]\n",
      " [ 0.21016127]\n",
      " [ 0.17423901]\n",
      " [ 0.04851113]\n",
      " [ 0.06048521]\n",
      " [ 0.04252408]\n",
      " [-0.43045226]\n",
      " [-0.20294465]\n",
      " [-0.41847817]\n",
      " [-0.11912606]\n",
      " [ 0.15627789]\n",
      " [-0.1251131 ]\n",
      " [-0.0113593 ]\n",
      " [ 0.15029084]\n",
      " [-0.10116493]\n",
      " [-0.04129451]\n",
      " [ 0.11436859]\n",
      " [-0.14906127]\n",
      " [ 0.12035563]\n",
      " [ 0.07844634]\n",
      " [-0.00537226]\n",
      " [ 0.2999669 ]\n",
      " [ 0.09042042]\n",
      " [ 0.12634268]\n",
      " [ 0.09042042]\n",
      " [ 0.10239451]\n",
      " [ 0.04252408]\n",
      " [ 0.07844634]\n",
      " [-0.14906127]\n",
      " [-0.04728155]\n",
      " [-0.07122972]\n",
      " [-0.23886691]\n",
      " [ 0.07844634]\n",
      " [-0.08919085]\n",
      " [-0.20294465]\n",
      " [ 0.01258887]\n",
      " [ 0.15029084]\n",
      " [ 0.07844634]\n",
      " [ 0.25805761]\n",
      " [ 0.08443338]\n",
      " [-0.04129451]\n",
      " [-0.04129451]\n",
      " [-0.23886691]\n",
      " [-0.17899648]\n",
      " [-0.14906127]\n",
      " [-0.02932042]\n",
      " [ 0.12634268]\n",
      " [ 0.05449817]\n",
      " [-0.27478916]\n",
      " [-0.13708719]\n",
      " [ 0.26404465]\n",
      " [ 0.03653704]\n",
      " [-0.17300944]\n",
      " [ 0.00660183]\n",
      " [-0.23886691]\n",
      " [-0.09517789]\n",
      " [-0.04129451]\n",
      " [-0.01734634]\n",
      " [ 0.24608352]\n",
      " [ 0.09042042]\n",
      " [-0.20294465]\n",
      " [ 0.04851113]\n",
      " [ 0.07245929]\n",
      " [ 0.05449817]\n",
      " [ 0.13232972]\n",
      " [-0.36459479]\n",
      " [ 0.03653704]\n",
      " [-0.4364393 ]\n",
      " [-0.04728155]\n",
      " [ 0.05449817]\n",
      " [-0.01734634]\n",
      " [-0.18498352]\n",
      " [ 0.05449817]\n",
      " [-0.21491874]\n",
      " [-0.00537226]\n",
      " [-0.34663367]\n",
      " [ 0.11436859]\n",
      " [ 0.09640746]\n",
      " [ 0.01857591]\n",
      " [ 0.20417423]\n",
      " [-0.35262071]\n",
      " [ 0.09042042]\n",
      " [ 0.15627789]\n",
      " [-0.26281507]\n",
      " [ 0.02456296]\n",
      " [ 0.03653704]\n",
      " [-0.18498352]\n",
      " [-0.34064662]\n",
      " [-0.05326859]\n",
      " [ 0.15627789]\n",
      " [ 0.53362549]\n",
      " [-0.00537226]\n",
      " [ 0.15627789]\n",
      " [-0.02932042]\n",
      " [-0.10715197]\n",
      " [ 0.03055   ]\n",
      " [ 0.13232972]\n",
      " [ 0.53362549]\n",
      " [ 0.17423901]\n",
      " [-0.09517789]\n",
      " [ 0.35983732]\n",
      " [ 0.1862131 ]\n",
      " [ 0.1862131 ]\n",
      " [-0.26281507]\n",
      " [-0.02333338]\n",
      " [-0.04728155]\n",
      " [ 0.19818718]\n",
      " [-0.44841339]\n",
      " [-0.40650409]\n",
      " [-0.22090578]\n",
      " [ 0.10838155]\n",
      " [-0.14906127]\n",
      " [-0.15504831]\n",
      " [ 0.13232972]\n",
      " [-0.01734634]\n",
      " [ 0.12035563]\n",
      " [ 0.24009648]\n",
      " [-0.07122972]\n",
      " [-0.31071141]\n",
      " [ 0.01857591]\n",
      " [ 0.22213535]\n",
      " [ 0.09640746]\n",
      " [-0.00537226]\n",
      " [-0.11313902]\n",
      " [ 0.13831676]\n",
      " [ 0.20417423]\n",
      " [-0.20893169]\n",
      " [ 0.16825197]\n",
      " [ 0.08443338]\n",
      " [ 0.09640746]\n",
      " [ 0.07245929]\n",
      " [ 0.1862131 ]\n",
      " [-0.02333338]\n",
      " [ 0.01258887]\n",
      " [ 0.03055   ]\n",
      " [ 0.09640746]\n",
      " [-0.13708719]\n",
      " [ 0.12634268]\n",
      " [ 0.12634268]\n",
      " [-0.26880212]\n",
      " [-0.05925564]\n",
      " [ 0.03055   ]\n",
      " [-0.22090578]\n",
      " [-0.03530747]\n",
      " [ 0.15029084]\n",
      " [-0.05925564]\n",
      " [ 0.23410944]\n",
      " [-0.43045226]\n",
      " [ 0.15627789]\n",
      " [-0.09517789]\n",
      " [-0.08919085]\n",
      " [ 0.29397986]\n",
      " [-0.2807762 ]\n",
      " [-0.0113593 ]\n",
      " [ 0.03653704]\n",
      " [ 0.12035563]\n",
      " [-0.45440043]\n",
      " [-0.30472437]\n",
      " [ 0.11436859]\n",
      " [ 0.05449817]\n",
      " [-0.13110014]\n",
      " [-0.13110014]\n",
      " [-0.10116493]\n",
      " [-0.31071141]\n",
      " [ 0.1443038 ]\n",
      " [-0.13708719]\n",
      " [ 0.22812239]\n",
      " [-0.04728155]\n",
      " [ 0.01258887]\n",
      " [ 0.16226493]\n",
      " [ 0.11436859]\n",
      " [ 0.03653704]\n",
      " [-0.17899648]\n",
      " [-0.37656888]\n",
      " [ 0.16226493]\n",
      " [-0.35860775]\n",
      " [-0.08320381]\n",
      " [ 0.15627789]\n",
      " [ 0.13232972]\n",
      " [ 0.19220014]\n",
      " [ 0.24608352]\n",
      " [-0.10715197]\n",
      " [ 0.1862131 ]\n",
      " [-0.11912606]\n",
      " [-0.11313902]\n",
      " [-0.15504831]\n",
      " [ 0.1443038 ]\n",
      " [ 0.08443338]\n",
      " [-0.40650409]\n",
      " [ 0.22812239]\n",
      " [ 0.02456296]\n",
      " [ 0.07844634]\n",
      " [ 0.02456296]\n",
      " [-0.35262071]\n",
      " [ 0.12634268]\n",
      " [ 0.15627789]\n",
      " [ 0.10239451]\n",
      " [ 0.00660183]\n",
      " [ 0.23410944]\n",
      " [-0.07721676]\n",
      " [ 0.18022606]\n",
      " [ 0.01258887]\n",
      " [ 0.12634268]\n",
      " [-0.3226855 ]\n",
      " [-0.08320381]\n",
      " [ 0.21016127]\n",
      " [-0.16103536]\n",
      " [-0.07721676]\n",
      " [ 0.00660183]\n",
      " [ 0.2999669 ]\n",
      " [ 0.28200577]\n",
      " [ 0.19818718]\n",
      " [ 0.03653704]\n",
      " [-0.01734634]\n",
      " [ 0.28200577]\n",
      " [ 0.1443038 ]\n",
      " [ 0.00660183]\n",
      " [-0.19695761]\n",
      " [-0.13708719]\n",
      " [-0.09517789]\n",
      " [ 0.01258887]\n",
      " [-0.08919085]\n",
      " [ 0.04252408]\n",
      " [-0.09517789]\n",
      " [ 0.09640746]\n",
      " [ 0.04252408]\n",
      " [-0.02932042]\n",
      " [-0.06524268]\n",
      " [-0.22090578]\n",
      " [-0.0113593 ]\n",
      " [ 0.21614831]\n",
      " [ 0.22213535]\n",
      " [-0.14307423]\n",
      " [-0.08320381]\n",
      " [-0.10715197]\n",
      " [-0.31071141]\n",
      " [ 0.13232972]\n",
      " [-0.4364393 ]\n",
      " [ 0.22812239]\n",
      " [ 0.19220014]\n",
      " [ 0.13232972]\n",
      " [-0.02333338]\n",
      " [ 0.24608352]\n",
      " [-0.26880212]\n",
      " [ 0.06647225]\n",
      " [ 0.24009648]\n",
      " [-0.44242634]\n",
      " [-0.19695761]\n",
      " [ 0.02456296]\n",
      " [ 0.22213535]\n",
      " [ 0.53362549]\n",
      " [ 0.16226493]\n",
      " [ 0.15029084]\n",
      " [ 0.27601873]\n",
      " [-0.35262071]\n",
      " [-0.05326859]\n",
      " [ 0.22213535]\n",
      " [ 0.00660183]\n",
      " [ 0.22213535]\n",
      " [-0.10715197]\n",
      " [ 0.18022606]\n",
      " [ 0.18022606]\n",
      " [ 0.13232972]\n",
      " [-0.25084099]\n",
      " [-0.14307423]\n",
      " [-0.02333338]\n",
      " [ 0.27003169]\n",
      " [-0.04728155]\n",
      " [ 0.31792803]\n",
      " [-0.01734634]\n",
      " [ 0.04252408]\n",
      " [-0.05326859]\n",
      " [-0.02333338]\n",
      " [ 0.20417423]\n",
      " [ 0.1443038 ]\n",
      " [ 0.03055   ]\n",
      " [ 0.02456296]\n",
      " [ 0.06048521]\n",
      " [-0.00537226]\n",
      " [ 0.08443338]\n",
      " [ 0.21016127]\n",
      " [ 0.18022606]\n",
      " [ 0.26404465]\n",
      " [-0.06524268]\n",
      " [ 0.09640746]\n",
      " [ 0.38378549]\n",
      " [-0.03530747]\n",
      " [-0.04728155]\n",
      " [ 0.12634268]\n",
      " [-0.04129451]\n",
      " [ 0.1862131 ]\n",
      " [ 0.22213535]\n",
      " [ 0.19818718]\n",
      " [-0.38854296]\n",
      " [-0.39453   ]\n",
      " [-0.05925564]\n",
      " [-0.25682803]\n",
      " [-0.40650409]\n",
      " [ 0.03055   ]\n",
      " [ 0.22213535]\n",
      " [ 0.04252408]\n",
      " [ 0.19818718]\n",
      " [ 0.22213535]\n",
      " [-0.01734634]\n",
      " [ 0.1443038 ]\n",
      " [ 0.06647225]\n",
      " [ 0.10838155]\n",
      " [ 0.21614831]\n",
      " [-0.02333338]\n",
      " [-0.46038747]\n",
      " [ 0.20417423]\n",
      " [ 0.13232972]\n",
      " [ 0.18022606]\n",
      " [ 0.15627789]\n",
      " [ 0.13232972]\n",
      " [ 0.17423901]\n",
      " [-0.19695761]\n",
      " [ 0.00061479]\n",
      " [ 0.25805761]\n",
      " [-0.05326859]\n",
      " [ 0.06048521]\n",
      " [ 0.13831676]\n",
      " [-0.13110014]\n",
      " [ 0.01258887]\n",
      " [ 0.07844634]\n",
      " [ 0.01857591]\n",
      " [-0.07122972]\n",
      " [-0.45440043]\n",
      " [-0.17899648]\n",
      " [ 0.07245929]\n",
      " [ 0.00061479]\n",
      " [ 0.12634268]\n",
      " [-0.01734634]\n",
      " [ 0.16825197]\n",
      " [-0.13110014]\n",
      " [ 0.10838155]\n",
      " [-0.32867254]\n",
      " [ 0.28799282]\n",
      " [ 0.06048521]\n",
      " [ 0.05449817]\n",
      " [-0.06524268]\n",
      " [ 0.23410944]\n",
      " [-0.0113593 ]\n",
      " [-0.40051705]\n",
      " [ 0.32391507]\n",
      " [ 0.19220014]\n",
      " [-0.31071141]\n",
      " [ 0.07245929]\n",
      " [ 0.07844634]\n",
      " [ 0.15029084]\n",
      " [-0.01734634]\n",
      " [-0.17300944]\n",
      " [-0.37058184]\n",
      " [-0.01734634]\n",
      " [-0.35860775]\n",
      " [ 0.17423901]\n",
      " [-0.18498352]\n",
      " [ 0.06048521]\n",
      " [ 0.09042042]\n",
      " [-0.31669846]\n",
      " [-0.2807762 ]\n",
      " [ 0.09640746]\n",
      " [-0.10116493]\n",
      " [ 0.09042042]\n",
      " [ 0.02456296]\n",
      " [ 0.31792803]\n",
      " [ 0.05449817]\n",
      " [ 0.01258887]\n",
      " [ 0.05449817]\n",
      " [ 0.17423901]\n",
      " [-0.37058184]\n",
      " [ 0.16226493]\n",
      " [ 0.07844634]\n",
      " [ 0.1862131 ]\n",
      " [-0.02333338]\n",
      " [-0.06524268]\n",
      " [-0.04129451]\n",
      " [ 0.16226493]\n",
      " [ 0.04252408]\n",
      " [ 0.11436859]\n",
      " [ 0.06048521]\n",
      " [-0.04129451]\n",
      " [ 0.17423901]\n",
      " [ 0.10239451]\n",
      " [ 0.10239451]\n",
      " [ 0.16226493]\n",
      " [ 0.1443038 ]\n",
      " [ 0.12634268]\n",
      " [ 0.11436859]\n",
      " [-0.04129451]\n",
      " [-0.15504831]\n",
      " [ 0.1862131 ]\n",
      " [ 0.10838155]\n",
      " [-0.21491874]\n",
      " [-0.27478916]\n",
      " [-0.34663367]\n",
      " [-0.08919085]\n",
      " [ 0.08443338]\n",
      " [ 0.18022606]\n",
      " [ 0.02456296]\n",
      " [-0.0113593 ]\n",
      " [ 0.00660183]\n",
      " [ 0.09042042]\n",
      " [-0.20294465]\n",
      " [ 0.12035563]\n",
      " [ 0.00660183]\n",
      " [-0.03530747]\n",
      " [ 0.24608352]\n",
      " [-0.24485395]\n",
      " [-0.46637451]\n",
      " [-0.27478916]\n",
      " [-0.14307423]\n",
      " [ 0.03653704]\n",
      " [ 0.05449817]\n",
      " [-0.14307423]\n",
      " [ 0.06048521]\n",
      " [ 0.13831676]\n",
      " [-0.19695761]\n",
      " [-0.26281507]\n",
      " [ 0.13232972]\n",
      " [ 0.31792803]\n",
      " [-0.0113593 ]\n",
      " [ 0.18022606]\n",
      " [-0.44242634]\n",
      " [-0.20893169]\n",
      " [ 0.16825197]\n",
      " [ 0.00061479]\n",
      " [ 0.12035563]\n",
      " [ 0.38977254]\n",
      " [-0.24485395]\n",
      " [ 0.15627789]\n",
      " [-0.02333338]\n",
      " [-0.08919085]\n",
      " [-0.04728155]\n",
      " [-0.05326859]\n",
      " [ 0.08443338]\n",
      " [-0.11313902]\n",
      " [-0.13708719]\n",
      " [ 0.08443338]\n",
      " [-0.22090578]\n",
      " [ 0.00061479]\n",
      " [-0.04728155]\n",
      " [ 0.1862131 ]\n",
      " [-0.1251131 ]\n",
      " [-0.28676324]\n",
      " [ 0.13232972]\n",
      " [-0.03530747]\n",
      " [ 0.01857591]\n",
      " [-0.00537226]\n",
      " [-0.02333338]\n",
      " [-0.2807762 ]\n",
      " [-0.04728155]\n",
      " [ 0.06647225]\n",
      " [ 0.24608352]\n",
      " [ 0.03653704]\n",
      " [-0.03530747]\n",
      " [-0.25682803]\n",
      " [ 0.16825197]\n",
      " [-0.22090578]\n",
      " [-0.02932042]\n",
      " [-0.04728155]\n",
      " [-0.07721676]\n",
      " [ 0.11436859]\n",
      " [-0.39453   ]\n",
      " [-0.31071141]\n",
      " [ 0.16226493]\n",
      " [ 0.07844634]\n",
      " [ 0.1443038 ]\n",
      " [ 0.22812239]\n",
      " [ 0.04252408]\n",
      " [-0.1670224 ]\n",
      " [ 0.02456296]\n",
      " [ 0.06048521]\n",
      " [ 0.05449817]\n",
      " [ 0.03055   ]\n",
      " [-0.11912606]\n",
      " [-0.3226855 ]\n",
      " [ 0.17423901]\n",
      " [-0.05326859]\n",
      " [ 0.00660183]\n",
      " [-0.31669846]\n",
      " [ 0.09042042]\n",
      " [ 0.09640746]\n",
      " [ 0.15627789]\n",
      " [-0.02932042]\n",
      " [ 0.33588916]\n",
      " [ 0.13232972]\n",
      " [ 0.11436859]\n",
      " [ 0.00660183]\n",
      " [ 0.11436859]\n",
      " [ 0.07245929]\n",
      " [-0.11313902]\n",
      " [-0.19097057]\n",
      " [ 0.12634268]\n",
      " [-0.15504831]\n",
      " [ 0.24009648]\n",
      " [-0.39453   ]\n",
      " [-0.24485395]\n",
      " [-0.08919085]\n",
      " [ 0.00061479]\n",
      " [ 0.07844634]\n",
      " [-0.35860775]\n",
      " [-0.19695761]\n",
      " [-0.04129451]\n",
      " [-0.09517789]\n",
      " [-0.0113593 ]\n",
      " [ 0.09042042]\n",
      " [-0.41249113]\n",
      " [ 0.19818718]\n",
      " [-0.29275029]\n",
      " [ 0.19220014]\n",
      " [ 0.12035563]\n",
      " [-0.00537226]\n",
      " [ 0.00061479]\n",
      " [-0.02932042]\n",
      " [ 0.16825197]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.6789 - acc: 0.6510\n",
      "Epoch 2/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.6593 - acc: 0.6510\n",
      "Epoch 3/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.6506 - acc: 0.6510\n",
      "Epoch 4/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.6434 - acc: 0.6510\n",
      "Epoch 5/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.6356 - acc: 0.6510\n",
      "Epoch 6/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.6242 - acc: 0.6510\n",
      "Epoch 7/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.6109 - acc: 0.6510\n",
      "Epoch 8/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5966 - acc: 0.6693\n",
      "Epoch 9/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5826 - acc: 0.6992\n",
      "Epoch 10/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5657 - acc: 0.7357\n",
      "Epoch 11/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5514 - acc: 0.7448\n",
      "Epoch 12/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5424 - acc: 0.7409\n",
      "Epoch 13/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5340 - acc: 0.7474\n",
      "Epoch 14/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5310 - acc: 0.7409\n",
      "Epoch 15/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5278 - acc: 0.7383\n",
      "Epoch 16/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5254 - acc: 0.7422\n",
      "Epoch 17/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5253 - acc: 0.7435\n",
      "Epoch 18/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5240 - acc: 0.7461\n",
      "Epoch 19/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5218 - acc: 0.7357\n",
      "Epoch 20/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5219 - acc: 0.7487\n",
      "Epoch 21/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5225 - acc: 0.7474\n",
      "Epoch 22/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5231 - acc: 0.7435\n",
      "Epoch 23/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5218 - acc: 0.7461\n",
      "Epoch 24/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5220 - acc: 0.7487\n",
      "Epoch 25/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5221 - acc: 0.7461\n",
      "Epoch 26/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5224 - acc: 0.7422\n",
      "Epoch 27/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5211 - acc: 0.7383\n",
      "Epoch 28/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5215 - acc: 0.7396\n",
      "Epoch 29/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5215 - acc: 0.7461\n",
      "Epoch 30/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5219 - acc: 0.7487\n",
      "Epoch 31/250\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.5216 - acc: 0.7370\n",
      "Epoch 32/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5216 - acc: 0.7474\n",
      "Epoch 33/250\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.5213 - acc: 0.7487\n",
      "Epoch 34/250\n",
      "768/768 [==============================] - 0s 205us/step - loss: 0.5231 - acc: 0.7409\n",
      "Epoch 35/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5219 - acc: 0.7396\n",
      "Epoch 36/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5195 - acc: 0.7474\n",
      "Epoch 37/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5224 - acc: 0.7422\n",
      "Epoch 38/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5221 - acc: 0.7331\n",
      "Epoch 39/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5220 - acc: 0.7357\n",
      "Epoch 40/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5217 - acc: 0.7435\n",
      "Epoch 41/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5216 - acc: 0.7474\n",
      "Epoch 42/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5213 - acc: 0.7409\n",
      "Epoch 43/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5220 - acc: 0.7435\n",
      "Epoch 44/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5214 - acc: 0.7500\n",
      "Epoch 45/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5212 - acc: 0.7422\n",
      "Epoch 46/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5205 - acc: 0.7448\n",
      "Epoch 47/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5219 - acc: 0.7422\n",
      "Epoch 48/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5230 - acc: 0.7461\n",
      "Epoch 49/250\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.5213 - acc: 0.7409\n",
      "Epoch 50/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5214 - acc: 0.7435\n",
      "Epoch 51/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5216 - acc: 0.7422\n",
      "Epoch 52/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5212 - acc: 0.7461\n",
      "Epoch 53/250\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5209 - acc: 0.7448\n",
      "Epoch 54/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5204 - acc: 0.7396\n",
      "Epoch 55/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5220 - acc: 0.7461\n",
      "Epoch 56/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5214 - acc: 0.7487\n",
      "Epoch 57/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5211 - acc: 0.7422\n",
      "Epoch 58/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5213 - acc: 0.7474\n",
      "Epoch 59/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5222 - acc: 0.7422\n",
      "Epoch 60/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5214 - acc: 0.7513\n",
      "Epoch 61/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5210 - acc: 0.7409\n",
      "Epoch 62/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5209 - acc: 0.7422\n",
      "Epoch 63/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5218 - acc: 0.7422\n",
      "Epoch 64/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5210 - acc: 0.7409\n",
      "Epoch 65/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5213 - acc: 0.7396\n",
      "Epoch 66/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5209 - acc: 0.7435\n",
      "Epoch 67/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5202 - acc: 0.7448\n",
      "Epoch 68/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5219 - acc: 0.7422\n",
      "Epoch 69/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5221 - acc: 0.7422\n",
      "Epoch 70/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5216 - acc: 0.7539\n",
      "Epoch 71/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5212 - acc: 0.7422\n",
      "Epoch 72/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5214 - acc: 0.7474\n",
      "Epoch 73/250\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.5216 - acc: 0.7474\n",
      "Epoch 74/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5217 - acc: 0.7435\n",
      "Epoch 75/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5216 - acc: 0.7474\n",
      "Epoch 76/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5225 - acc: 0.7448\n",
      "Epoch 77/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5219 - acc: 0.7448\n",
      "Epoch 78/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5217 - acc: 0.7474\n",
      "Epoch 79/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5220 - acc: 0.7461\n",
      "Epoch 80/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5209 - acc: 0.7513\n",
      "Epoch 81/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5207 - acc: 0.7487\n",
      "Epoch 82/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5204 - acc: 0.7422\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 200us/step - loss: 0.5216 - acc: 0.7422\n",
      "Epoch 84/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5205 - acc: 0.7500\n",
      "Epoch 85/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5224 - acc: 0.7396\n",
      "Epoch 86/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5209 - acc: 0.7487\n",
      "Epoch 87/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5204 - acc: 0.7396\n",
      "Epoch 88/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5238 - acc: 0.7409\n",
      "Epoch 89/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5221 - acc: 0.7448\n",
      "Epoch 90/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5206 - acc: 0.7474\n",
      "Epoch 91/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5212 - acc: 0.7435\n",
      "Epoch 92/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5209 - acc: 0.7409\n",
      "Epoch 93/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5231 - acc: 0.7461\n",
      "Epoch 94/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5200 - acc: 0.7409\n",
      "Epoch 95/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5221 - acc: 0.7487\n",
      "Epoch 96/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5212 - acc: 0.7422\n",
      "Epoch 97/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5211 - acc: 0.7461\n",
      "Epoch 98/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5220 - acc: 0.7435\n",
      "Epoch 99/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5213 - acc: 0.7435\n",
      "Epoch 100/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5221 - acc: 0.7461 0s - loss: 0.5285 - acc: 0.74\n",
      "Epoch 101/250\n",
      "768/768 [==============================] - 0s 257us/step - loss: 0.5209 - acc: 0.7461\n",
      "Epoch 102/250\n",
      "768/768 [==============================] - 0s 216us/step - loss: 0.5209 - acc: 0.7396\n",
      "Epoch 103/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5223 - acc: 0.7487\n",
      "Epoch 104/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5207 - acc: 0.7370\n",
      "Epoch 105/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5219 - acc: 0.7448\n",
      "Epoch 106/250\n",
      "768/768 [==============================] - 0s 240us/step - loss: 0.5196 - acc: 0.7422\n",
      "Epoch 107/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5223 - acc: 0.7461\n",
      "Epoch 108/250\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5212 - acc: 0.7396\n",
      "Epoch 109/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5205 - acc: 0.7461\n",
      "Epoch 110/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5209 - acc: 0.7461\n",
      "Epoch 111/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5203 - acc: 0.7487\n",
      "Epoch 112/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5233 - acc: 0.7396\n",
      "Epoch 113/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5214 - acc: 0.7409\n",
      "Epoch 114/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5205 - acc: 0.7526\n",
      "Epoch 115/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5230 - acc: 0.7435\n",
      "Epoch 116/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5212 - acc: 0.7461\n",
      "Epoch 117/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5204 - acc: 0.7422\n",
      "Epoch 118/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5226 - acc: 0.7435\n",
      "Epoch 119/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5217 - acc: 0.7422\n",
      "Epoch 120/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5212 - acc: 0.7435\n",
      "Epoch 121/250\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.5225 - acc: 0.7396\n",
      "Epoch 122/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5201 - acc: 0.7474\n",
      "Epoch 123/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5213 - acc: 0.7461\n",
      "Epoch 124/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5215 - acc: 0.7500\n",
      "Epoch 125/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5230 - acc: 0.7383\n",
      "Epoch 126/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5211 - acc: 0.7383\n",
      "Epoch 127/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5208 - acc: 0.7409\n",
      "Epoch 128/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5238 - acc: 0.7448\n",
      "Epoch 129/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5205 - acc: 0.7422\n",
      "Epoch 130/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5214 - acc: 0.7370\n",
      "Epoch 131/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5206 - acc: 0.7435\n",
      "Epoch 132/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5213 - acc: 0.7513\n",
      "Epoch 133/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5217 - acc: 0.7435\n",
      "Epoch 134/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5205 - acc: 0.7487\n",
      "Epoch 135/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5199 - acc: 0.7487\n",
      "Epoch 136/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5227 - acc: 0.7396\n",
      "Epoch 137/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5216 - acc: 0.7409\n",
      "Epoch 138/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5202 - acc: 0.7500\n",
      "Epoch 139/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5205 - acc: 0.7422\n",
      "Epoch 140/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5210 - acc: 0.7422\n",
      "Epoch 141/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5207 - acc: 0.7409\n",
      "Epoch 142/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5210 - acc: 0.7487\n",
      "Epoch 143/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5218 - acc: 0.7448\n",
      "Epoch 144/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5212 - acc: 0.7500\n",
      "Epoch 145/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5207 - acc: 0.7422\n",
      "Epoch 146/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5200 - acc: 0.7396\n",
      "Epoch 147/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5212 - acc: 0.7448\n",
      "Epoch 148/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5204 - acc: 0.7383\n",
      "Epoch 149/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5213 - acc: 0.7422\n",
      "Epoch 150/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5221 - acc: 0.7422\n",
      "Epoch 151/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5195 - acc: 0.7396\n",
      "Epoch 152/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5218 - acc: 0.7474\n",
      "Epoch 153/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5210 - acc: 0.7409\n",
      "Epoch 154/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5205 - acc: 0.7461\n",
      "Epoch 155/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5208 - acc: 0.7422\n",
      "Epoch 156/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5209 - acc: 0.7422\n",
      "Epoch 157/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5213 - acc: 0.7422\n",
      "Epoch 158/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5215 - acc: 0.7370\n",
      "Epoch 159/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5207 - acc: 0.7487\n",
      "Epoch 160/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5208 - acc: 0.7474\n",
      "Epoch 161/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5206 - acc: 0.7370\n",
      "Epoch 162/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5206 - acc: 0.7461\n",
      "Epoch 163/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5210 - acc: 0.7474\n",
      "Epoch 164/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 200us/step - loss: 0.5225 - acc: 0.7409\n",
      "Epoch 165/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5217 - acc: 0.7448\n",
      "Epoch 166/250\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5214 - acc: 0.7474\n",
      "Epoch 167/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5210 - acc: 0.7461\n",
      "Epoch 168/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5202 - acc: 0.7409\n",
      "Epoch 169/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5217 - acc: 0.7448\n",
      "Epoch 170/250\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.5056 - acc: 0.756 - 0s 212us/step - loss: 0.5211 - acc: 0.7461\n",
      "Epoch 171/250\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5205 - acc: 0.7409\n",
      "Epoch 172/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5223 - acc: 0.7435\n",
      "Epoch 173/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5208 - acc: 0.7396\n",
      "Epoch 174/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5214 - acc: 0.7409\n",
      "Epoch 175/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5209 - acc: 0.7474\n",
      "Epoch 176/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5211 - acc: 0.7383\n",
      "Epoch 177/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5206 - acc: 0.7409\n",
      "Epoch 178/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5234 - acc: 0.7461\n",
      "Epoch 179/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5214 - acc: 0.7435\n",
      "Epoch 180/250\n",
      "768/768 [==============================] - 0s 412us/step - loss: 0.5215 - acc: 0.7370\n",
      "Epoch 181/250\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.5206 - acc: 0.7435\n",
      "Epoch 182/250\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5207 - acc: 0.7448\n",
      "Epoch 183/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5218 - acc: 0.7422\n",
      "Epoch 184/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5207 - acc: 0.7396\n",
      "Epoch 185/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5215 - acc: 0.7487\n",
      "Epoch 186/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5205 - acc: 0.7474\n",
      "Epoch 187/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5209 - acc: 0.7435\n",
      "Epoch 188/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5213 - acc: 0.7422\n",
      "Epoch 189/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5208 - acc: 0.7448\n",
      "Epoch 190/250\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5207 - acc: 0.7448\n",
      "Epoch 191/250\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5221 - acc: 0.7474\n",
      "Epoch 192/250\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5207 - acc: 0.7422\n",
      "Epoch 193/250\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.5219 - acc: 0.7357\n",
      "Epoch 194/250\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5199 - acc: 0.7474\n",
      "Epoch 195/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5207 - acc: 0.7461\n",
      "Epoch 196/250\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5224 - acc: 0.7526\n",
      "Epoch 197/250\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5211 - acc: 0.7409\n",
      "Epoch 198/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5205 - acc: 0.7448\n",
      "Epoch 199/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5209 - acc: 0.7448\n",
      "Epoch 200/250\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.5211 - acc: 0.7370\n",
      "Epoch 201/250\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5205 - acc: 0.7448\n",
      "Epoch 202/250\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5219 - acc: 0.7370\n",
      "Epoch 203/250\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.5210 - acc: 0.7396\n",
      "Epoch 204/250\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.5215 - acc: 0.7383\n",
      "Epoch 205/250\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.5211 - acc: 0.7448\n",
      "Epoch 206/250\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5191 - acc: 0.7487\n",
      "Epoch 207/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5223 - acc: 0.7383\n",
      "Epoch 208/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5215 - acc: 0.7487\n",
      "Epoch 209/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5208 - acc: 0.7422\n",
      "Epoch 210/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5211 - acc: 0.7409\n",
      "Epoch 211/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5206 - acc: 0.7448\n",
      "Epoch 212/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5212 - acc: 0.7422\n",
      "Epoch 213/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5203 - acc: 0.7448\n",
      "Epoch 214/250\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5204 - acc: 0.7474\n",
      "Epoch 215/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5237 - acc: 0.7318\n",
      "Epoch 216/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5226 - acc: 0.7370\n",
      "Epoch 217/250\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5203 - acc: 0.7461\n",
      "Epoch 218/250\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5203 - acc: 0.7435\n",
      "Epoch 219/250\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.5207 - acc: 0.7461\n",
      "Epoch 220/250\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5212 - acc: 0.7396\n",
      "Epoch 221/250\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.5208 - acc: 0.7396\n",
      "Epoch 222/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5209 - acc: 0.7435\n",
      "Epoch 223/250\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.5204 - acc: 0.7435\n",
      "Epoch 224/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5208 - acc: 0.7474\n",
      "Epoch 225/250\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5211 - acc: 0.7409\n",
      "Epoch 226/250\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.5211 - acc: 0.7435\n",
      "Epoch 227/250\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5202 - acc: 0.7396\n",
      "Epoch 228/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5220 - acc: 0.7448\n",
      "Epoch 229/250\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5187 - acc: 0.7461\n",
      "Epoch 230/250\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.5242 - acc: 0.7435\n",
      "Epoch 231/250\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5209 - acc: 0.7370\n",
      "Epoch 232/250\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.5224 - acc: 0.7474\n",
      "Epoch 233/250\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.5209 - acc: 0.7461\n",
      "Epoch 234/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5211 - acc: 0.7526\n",
      "Epoch 235/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5204 - acc: 0.7383\n",
      "Epoch 236/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5216 - acc: 0.7474\n",
      "Epoch 237/250\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.5205 - acc: 0.7383\n",
      "Epoch 238/250\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5211 - acc: 0.7461\n",
      "Epoch 239/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5211 - acc: 0.7448\n",
      "Epoch 240/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5212 - acc: 0.7422\n",
      "Epoch 241/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5190 - acc: 0.7435\n",
      "Epoch 242/250\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5217 - acc: 0.7435\n",
      "Epoch 243/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5202 - acc: 0.7513\n",
      "Epoch 244/250\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5213 - acc: 0.7461\n",
      "Epoch 245/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 241us/step - loss: 0.5212 - acc: 0.7487\n",
      "Epoch 246/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5211 - acc: 0.7422\n",
      "Epoch 247/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5202 - acc: 0.7487\n",
      "Epoch 248/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5213 - acc: 0.7370\n",
      "Epoch 249/250\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5208 - acc: 0.7461\n",
      "Epoch 250/250\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5214 - acc: 0.7409\n",
      "768/768 [==============================] - 1s 722us/step\n",
      "\n",
      "acc: 74.6094%\n"
     ]
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_std_impute_scaling_age_bmi.txt\", delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:1]\n",
    "Y = dataset[:,1]\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=1).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=1, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=250, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
