{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Create your first MLP in Keras\n",
    "import time\n",
    "start = time.time()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"diabetes\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nazmus Sakib\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nazmus Sakib\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 2.2927 - acc: 0.6094\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.7583 - acc: 0.6445\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.7034 - acc: 0.6615\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.6687 - acc: 0.6745\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6598 - acc: 0.6667\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6341 - acc: 0.6927\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6451 - acc: 0.6914\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6193 - acc: 0.6888\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6307 - acc: 0.6875\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5963 - acc: 0.7057\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5984 - acc: 0.7005\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5950 - acc: 0.7096\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5678 - acc: 0.7057\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5872 - acc: 0.7044\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.5866 - acc: 0.7005\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5759 - acc: 0.6966\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5661 - acc: 0.7174\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5520 - acc: 0.7122\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5606 - acc: 0.7109\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5591 - acc: 0.7135\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5505 - acc: 0.7109\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5492 - acc: 0.7292\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5537 - acc: 0.7253\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5508 - acc: 0.7383\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5397 - acc: 0.7383\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5464 - acc: 0.7266\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5343 - acc: 0.7396\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5442 - acc: 0.7292\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5254 - acc: 0.7500\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5221 - acc: 0.7448\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5337 - acc: 0.7240\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5344 - acc: 0.7461\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5283 - acc: 0.7487\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5358 - acc: 0.7409\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5253 - acc: 0.7474\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5209 - acc: 0.7513\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5135 - acc: 0.7604\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5106 - acc: 0.7448\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5206 - acc: 0.7500\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5110 - acc: 0.7409\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5156 - acc: 0.7487\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5249 - acc: 0.7357\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5020 - acc: 0.7695\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5060 - acc: 0.7448\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5023 - acc: 0.7578\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5113 - acc: 0.7734\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5074 - acc: 0.7526\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5064 - acc: 0.7669\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5031 - acc: 0.7617\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5095 - acc: 0.7500\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5125 - acc: 0.7578\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5021 - acc: 0.7591\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5052 - acc: 0.7591\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5040 - acc: 0.7513\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4992 - acc: 0.7708\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5039 - acc: 0.7656\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5005 - acc: 0.7643\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4902 - acc: 0.7773\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4918 - acc: 0.7669\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5013 - acc: 0.7695\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4956 - acc: 0.7643\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4949 - acc: 0.7656\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4943 - acc: 0.7708\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4984 - acc: 0.7513\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4900 - acc: 0.7695\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4888 - acc: 0.7747\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4885 - acc: 0.7565\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4916 - acc: 0.7760\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4925 - acc: 0.7591\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4881 - acc: 0.7552\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4843 - acc: 0.7682\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4880 - acc: 0.7760\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4862 - acc: 0.7617\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4812 - acc: 0.7734\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4833 - acc: 0.7747\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4830 - acc: 0.7786\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4840 - acc: 0.7773\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4743 - acc: 0.7839\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4823 - acc: 0.7721\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4791 - acc: 0.7799\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 203us/step - loss: 0.4763 - acc: 0.7786\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4682 - acc: 0.7812\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4717 - acc: 0.7826\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4678 - acc: 0.7734\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4791 - acc: 0.7643\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4798 - acc: 0.7799\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4689 - acc: 0.7852\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4712 - acc: 0.7839\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4692 - acc: 0.7917\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4693 - acc: 0.7721\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.4720 - acc: 0.7721\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4690 - acc: 0.7747\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4697 - acc: 0.7812\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4705 - acc: 0.7708\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.4749 - acc: 0.7747\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4662 - acc: 0.7786\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4649 - acc: 0.7917\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4687 - acc: 0.7865\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4614 - acc: 0.7839\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4616 - acc: 0.7852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e034df5f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 203us/step\n",
      "\n",
      "acc: 79.69%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.90174984931946\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_bmi = dataset['BMI'].median()\n",
    "dataset['BMI'] = dataset['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)\n",
    "\n",
    "median_bloodp = dataset['BloodPressure'].median()\n",
    "dataset['BloodPressure'] = dataset['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)\n",
    "\n",
    "median_plglcconc = dataset['Glucose'].median()\n",
    "dataset['Glucose'] = dataset['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)\n",
    "\n",
    "median_skinthick = dataset['SkinThickness'].median()\n",
    "dataset['SkinThickness'] = dataset['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)\n",
    "\n",
    "median_Insulin = dataset['Insulin'].median()\n",
    "dataset['Insulin'] = dataset['Insulin'].replace(\n",
    "    to_replace=0, value=median_Insulin)\n",
    "\n",
    "median_DiabetesPedigreeFunction = dataset['DiabetesPedigreeFunction'].median()\n",
    "dataset['DiabetesPedigreeFunction'] = dataset['DiabetesPedigreeFunction'].replace(\n",
    "    to_replace=0, value=median_DiabetesPedigreeFunction)\n",
    "\n",
    "median_Age = dataset['Age'].median()\n",
    "dataset['Age'] = dataset['Age'].replace(\n",
    "    to_replace=0, value=median_Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35     30.5  33.6   \n",
       "1            1       85             66             29     30.5  26.6   \n",
       "2            8      183             64             23     30.5  23.3   \n",
       "3            1       89             66             23     94.0  28.1   \n",
       "4            0      137             40             35    168.0  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"diabetes_impute.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_median_impute_.txt\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 1.1951 - acc: 0.6315\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.7431 - acc: 0.6641\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6324 - acc: 0.6758\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6166 - acc: 0.6901\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6167 - acc: 0.6914\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5947 - acc: 0.7044\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5899 - acc: 0.7122\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5946 - acc: 0.6823\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5844 - acc: 0.6979\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5760 - acc: 0.7148\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5742 - acc: 0.7135\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5720 - acc: 0.7031\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5626 - acc: 0.7240\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5621 - acc: 0.7083\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5589 - acc: 0.7214\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5631 - acc: 0.7344\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5550 - acc: 0.7227\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5535 - acc: 0.7227\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5550 - acc: 0.7266\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5523 - acc: 0.7279\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5443 - acc: 0.7383\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5446 - acc: 0.7331\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5454 - acc: 0.7435\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5347 - acc: 0.7461\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5437 - acc: 0.7187\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5451 - acc: 0.7161\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5387 - acc: 0.7474\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5408 - acc: 0.7305\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.5336 - acc: 0.7474\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5385 - acc: 0.7383\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5344 - acc: 0.7344\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5302 - acc: 0.7474\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5351 - acc: 0.7344\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5330 - acc: 0.7500\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5291 - acc: 0.7474\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5261 - acc: 0.7357\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5326 - acc: 0.7409\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5211 - acc: 0.7448\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5221 - acc: 0.7344\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5206 - acc: 0.7396\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5226 - acc: 0.7500\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5225 - acc: 0.7526\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5279 - acc: 0.7409\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5194 - acc: 0.7461\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5167 - acc: 0.7461\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5224 - acc: 0.7513\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5120 - acc: 0.7526\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5151 - acc: 0.7539\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5119 - acc: 0.7539\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5239 - acc: 0.7617\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5122 - acc: 0.7513\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5194 - acc: 0.7617\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5102 - acc: 0.7643\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5063 - acc: 0.7630\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5061 - acc: 0.7565\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5032 - acc: 0.7578\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5116 - acc: 0.7591\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5019 - acc: 0.7643\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5053 - acc: 0.7669\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4983 - acc: 0.7826\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5072 - acc: 0.7617\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4993 - acc: 0.7513\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4982 - acc: 0.7773\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4954 - acc: 0.7656\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4944 - acc: 0.7591\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4891 - acc: 0.7617\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4983 - acc: 0.7630\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5007 - acc: 0.7552\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4904 - acc: 0.7617\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4890 - acc: 0.7760\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4950 - acc: 0.7578\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4881 - acc: 0.7708\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4925 - acc: 0.7734\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4940 - acc: 0.7604\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4933 - acc: 0.7747\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4823 - acc: 0.7826\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4894 - acc: 0.7760\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4885 - acc: 0.7839\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4863 - acc: 0.7799\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4900 - acc: 0.7656\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4865 - acc: 0.7643\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4858 - acc: 0.7578\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 264us/step - loss: 0.4859 - acc: 0.7812\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4833 - acc: 0.7721\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4779 - acc: 0.7734\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4806 - acc: 0.7708\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4765 - acc: 0.7878\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4810 - acc: 0.7721\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4740 - acc: 0.7826\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4782 - acc: 0.7878\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4774 - acc: 0.7799\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4737 - acc: 0.7708\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4731 - acc: 0.7799\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4826 - acc: 0.7617\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4723 - acc: 0.7813\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4863 - acc: 0.7760\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4737 - acc: 0.7656\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4801 - acc: 0.7852\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4778 - acc: 0.7813\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 204us/step - loss: 0.4703 - acc: 0.7943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e06bcfba8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 244us/step\n",
      "\n",
      "acc: 74.87%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## impute in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-60.66982506  35.39041967]\n",
      " [-67.80527165 -30.1054099 ]\n",
      " [-57.15898153  64.80757497]\n",
      " ...\n",
      " [ 16.99436197  -3.47955518]\n",
      " [-63.35769843  11.25283709]\n",
      " [-66.83508906 -22.72874459]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy\n",
    "\n",
    "dataset = numpy.loadtxt(\"diabetes_median_impute_.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_16_input to have shape (8,) but got array with shape (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-dae2643033f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Nadam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_16_input to have shape (8,) but got array with shape (2,)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(train_set, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.impute & scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_bmi = dataset['BMI'].median()\n",
    "dataset['BMI'] = dataset['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)\n",
    "\n",
    "median_bloodp = dataset['BloodPressure'].median()\n",
    "dataset['BloodPressure'] = dataset['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)\n",
    "\n",
    "median_plglcconc = dataset['Glucose'].median()\n",
    "dataset['Glucose'] = dataset['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)\n",
    "\n",
    "median_skinthick = dataset['SkinThickness'].median()\n",
    "dataset['SkinThickness'] = dataset['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)\n",
    "\n",
    "median_Insulin = dataset['Insulin'].median()\n",
    "dataset['Insulin'] = dataset['Insulin'].replace(\n",
    "    to_replace=0, value=median_Insulin)\n",
    "\n",
    "median_DiabetesPedigreeFunction = dataset['DiabetesPedigreeFunction'].median()\n",
    "dataset['DiabetesPedigreeFunction'] = dataset['DiabetesPedigreeFunction'].replace(\n",
    "    to_replace=0, value=median_DiabetesPedigreeFunction)\n",
    "\n",
    "median_Age = dataset['Age'].median()\n",
    "dataset['Age'] = dataset['Age'].replace(\n",
    "    to_replace=0, value=median_Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(\n",
    "    dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set_labels = train_set[\"Outcome\"].copy()\n",
    "train_set = train_set.drop(\"Outcome\", axis=1)\n",
    "\n",
    "test_set_labels = test_set[\"Outcome\"].copy()\n",
    "test_set = test_set.drop(\"Outcome\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nazmus Sakib\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.282209</td>\n",
       "      <td>0.096499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.438710</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.204499</td>\n",
       "      <td>0.514091</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>0.214724</td>\n",
       "      <td>0.245944</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754839</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.075665</td>\n",
       "      <td>0.075149</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.572597</td>\n",
       "      <td>0.068318</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.117647  0.258065  0.489796  0.272727  0.019832  0.282209  0.096499   \n",
       "1  0.529412  0.438710  0.591837  0.290909  0.019832  0.204499  0.514091   \n",
       "2  0.058824  0.612903  0.224490  0.200000  0.082933  0.214724  0.245944   \n",
       "3  0.000000  0.754839  0.265306  0.272727  0.019832  0.075665  0.075149   \n",
       "4  0.352941  0.580645  0.571429  0.527273  0.427885  0.572597  0.068318   \n",
       "\n",
       "          7  \n",
       "0  0.000000  \n",
       "1  0.483333  \n",
       "2  0.016667  \n",
       "3  0.733333  \n",
       "4  0.416667  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler as Scaler\n",
    "\n",
    "scaler = Scaler()\n",
    "scaler.fit(train_set)\n",
    "train_set_scaled = scaler.transform(train_set)\n",
    "test_set_scaled = scaler.transform(test_set)\n",
    "\n",
    "df = pd.DataFrame(data=train_set_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"diabetes_impute_scaling.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_median_impute_scaling.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.6609 - acc: 0.6484\n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6209 - acc: 0.6523\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5855 - acc: 0.6810\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5513 - acc: 0.7318\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5210 - acc: 0.7487\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4986 - acc: 0.7578\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4846 - acc: 0.7630\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4722 - acc: 0.7539\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4688 - acc: 0.7643\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4610 - acc: 0.7812\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4549 - acc: 0.7799\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4522 - acc: 0.7799\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4507 - acc: 0.7839\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4430 - acc: 0.7812\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4433 - acc: 0.7852\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4453 - acc: 0.7812\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4423 - acc: 0.7878\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4427 - acc: 0.7708\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4416 - acc: 0.7786\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4405 - acc: 0.7930\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4395 - acc: 0.7826\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4396 - acc: 0.7760\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4387 - acc: 0.7878\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4356 - acc: 0.7865\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4399 - acc: 0.7812\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4369 - acc: 0.7839\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4368 - acc: 0.7799\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4347 - acc: 0.7852\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4368 - acc: 0.7721\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4331 - acc: 0.7891\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4333 - acc: 0.7799\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4341 - acc: 0.7852\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4344 - acc: 0.7865\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4329 - acc: 0.7826\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4329 - acc: 0.7747\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4335 - acc: 0.7930\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4310 - acc: 0.7852\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4325 - acc: 0.7852\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4319 - acc: 0.7773\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4311 - acc: 0.7812\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4328 - acc: 0.7878\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4323 - acc: 0.7904\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4285 - acc: 0.7969\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4307 - acc: 0.8008\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4291 - acc: 0.7878\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4312 - acc: 0.7904\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4286 - acc: 0.7891\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4284 - acc: 0.7878\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4296 - acc: 0.7852\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4297 - acc: 0.7839\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4307 - acc: 0.7826\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4287 - acc: 0.7826\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4294 - acc: 0.7826\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4290 - acc: 0.7826\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4308 - acc: 0.7852\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4291 - acc: 0.7865\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4278 - acc: 0.7865\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4301 - acc: 0.7878\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4307 - acc: 0.7826\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4271 - acc: 0.7826\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4278 - acc: 0.7904\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4299 - acc: 0.7878\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4273 - acc: 0.7878\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4302 - acc: 0.7878\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4279 - acc: 0.7865\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4255 - acc: 0.7865\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4261 - acc: 0.7904\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4252 - acc: 0.7852\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4264 - acc: 0.7891\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4263 - acc: 0.7904\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4269 - acc: 0.7852\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4283 - acc: 0.7865\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4249 - acc: 0.7878\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4264 - acc: 0.7812\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4276 - acc: 0.7839\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4255 - acc: 0.7930\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4256 - acc: 0.7969\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4260 - acc: 0.7917\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4249 - acc: 0.7878\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4231 - acc: 0.7943\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4257 - acc: 0.7891\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4246 - acc: 0.7865\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4254 - acc: 0.7917\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.4284 - acc: 0.7865\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4257 - acc: 0.7826\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4264 - acc: 0.7799\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4259 - acc: 0.7760\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4263 - acc: 0.7865\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4244 - acc: 0.7891\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4249 - acc: 0.7865\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4230 - acc: 0.7878\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4260 - acc: 0.7826\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4251 - acc: 0.7904\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4241 - acc: 0.7943\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4247 - acc: 0.7930\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4239 - acc: 0.7904\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4225 - acc: 0.7839\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4232 - acc: 0.7812\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4238 - acc: 0.7826\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4246 - acc: 0.7878\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4248 - acc: 0.7839\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4213 - acc: 0.7982\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4253 - acc: 0.7799\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4239 - acc: 0.7852\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4224 - acc: 0.7891\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4251 - acc: 0.7813\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4251 - acc: 0.7917\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4234 - acc: 0.7799\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4252 - acc: 0.7826\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4233 - acc: 0.7878 0s - loss: 0.4215 - acc: 0.80\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4230 - acc: 0.7826\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4229 - acc: 0.7865\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4233 - acc: 0.7917\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4235 - acc: 0.7799\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4251 - acc: 0.7865\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4241 - acc: 0.7878\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4265 - acc: 0.7995\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4224 - acc: 0.7812\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4212 - acc: 0.7891\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4230 - acc: 0.7891\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4242 - acc: 0.7852\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4228 - acc: 0.7865\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4250 - acc: 0.7878\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4239 - acc: 0.7956\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4207 - acc: 0.7917\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4210 - acc: 0.7930\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4222 - acc: 0.7852\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4217 - acc: 0.7878\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4219 - acc: 0.7865\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4235 - acc: 0.7852\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4235 - acc: 0.7839\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4229 - acc: 0.7852\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4206 - acc: 0.7930\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4238 - acc: 0.7878\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4227 - acc: 0.7904\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4238 - acc: 0.7891\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4248 - acc: 0.7852\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4225 - acc: 0.7865\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4216 - acc: 0.7878\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4216 - acc: 0.7812\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4208 - acc: 0.7839\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 0s 210us/step - loss: 0.4228 - acc: 0.7865\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4215 - acc: 0.7799\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4246 - acc: 0.7930\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4206 - acc: 0.7852\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4195 - acc: 0.7943\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4241 - acc: 0.7904\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.4199 - acc: 0.7891\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4230 - acc: 0.7943 0s - loss: 0.3948 - acc: 0.7\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.4216 - acc: 0.7904\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4271 - acc: 0.7708\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4230 - acc: 0.7852\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4254 - acc: 0.7852\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4222 - acc: 0.7930\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4200 - acc: 0.7878\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4212 - acc: 0.7878\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4211 - acc: 0.7930\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4173 - acc: 0.8034\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4225 - acc: 0.7930\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4220 - acc: 0.7891\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4230 - acc: 0.7878\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4203 - acc: 0.7943\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4219 - acc: 0.7826\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 203us/step - loss: 0.4227 - acc: 0.7786\n",
      "Epoch 165/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4231 - acc: 0.7826\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4231 - acc: 0.7878\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4228 - acc: 0.7943\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4209 - acc: 0.7878\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4216 - acc: 0.7812\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4199 - acc: 0.7904\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4210 - acc: 0.7799\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4220 - acc: 0.7865\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4212 - acc: 0.7839\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4209 - acc: 0.7839\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4186 - acc: 0.7904\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4249 - acc: 0.7799\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4208 - acc: 0.7878\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4184 - acc: 0.7891\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4211 - acc: 0.7878\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4212 - acc: 0.7904\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4209 - acc: 0.7839\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4203 - acc: 0.7812\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4208 - acc: 0.7799\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4204 - acc: 0.7812\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4206 - acc: 0.7852\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.4282 - acc: 0.779 - 0s 142us/step - loss: 0.4204 - acc: 0.7786\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4231 - acc: 0.7826\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4199 - acc: 0.7826\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4180 - acc: 0.7956\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4192 - acc: 0.7969\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.4201 - acc: 0.7904\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4195 - acc: 0.7865\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4193 - acc: 0.7891\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4185 - acc: 0.7904\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4191 - acc: 0.7878\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4202 - acc: 0.7865\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4208 - acc: 0.7904\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4187 - acc: 0.7878\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4201 - acc: 0.7943\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4194 - acc: 0.7826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f208660400>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 264us/step\n",
      "\n",
      "acc: 78.78%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "\n",
    "median_bmi = dataset['BMI'].median()\n",
    "dataset['BMI'] = dataset['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)\n",
    "\n",
    "median_bloodp = dataset['BloodPressure'].median()\n",
    "dataset['BloodPressure'] = dataset['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)\n",
    "\n",
    "median_plglcconc = dataset['Glucose'].median()\n",
    "dataset['Glucose'] = dataset['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)\n",
    "\n",
    "median_skinthick = dataset['SkinThickness'].median()\n",
    "dataset['SkinThickness'] = dataset['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)\n",
    "\n",
    "median_Insulin = dataset['Insulin'].median()\n",
    "dataset['Insulin'] = dataset['Insulin'].replace(\n",
    "    to_replace=0, value=median_Insulin)\n",
    "\n",
    "median_DiabetesPedigreeFunction = dataset['DiabetesPedigreeFunction'].median()\n",
    "dataset['DiabetesPedigreeFunction'] = dataset['DiabetesPedigreeFunction'].replace(\n",
    "    to_replace=0, value=median_DiabetesPedigreeFunction)\n",
    "\n",
    "median_Age = dataset['Age'].median()\n",
    "dataset['Age'] = dataset['Age'].replace(\n",
    "    to_replace=0, value=median_Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(\n",
    "    dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set_labels = train_set[\"Outcome\"].copy()\n",
    "train_set = train_set.drop(\"Outcome\", axis=1)\n",
    "\n",
    "test_set_labels = test_set[\"Outcome\"].copy()\n",
    "test_set = test_set.drop(\"Outcome\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016239</td>\n",
       "      <td>0.682041</td>\n",
       "      <td>0.584606</td>\n",
       "      <td>0.186749</td>\n",
       "      <td>0.247646</td>\n",
       "      <td>0.259825</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.170510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057911</td>\n",
       "      <td>0.720676</td>\n",
       "      <td>0.527638</td>\n",
       "      <td>0.154431</td>\n",
       "      <td>0.196256</td>\n",
       "      <td>0.181456</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.321731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.802569</td>\n",
       "      <td>0.265598</td>\n",
       "      <td>0.109704</td>\n",
       "      <td>0.479232</td>\n",
       "      <td>0.165710</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.127025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865730</td>\n",
       "      <td>0.268860</td>\n",
       "      <td>0.123676</td>\n",
       "      <td>0.164005</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.349518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014686</td>\n",
       "      <td>0.327991</td>\n",
       "      <td>0.195815</td>\n",
       "      <td>0.090565</td>\n",
       "      <td>0.905646</td>\n",
       "      <td>0.113083</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.112594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.016239  0.682041  0.584606  0.186749  0.247646  0.259825  0.002468   \n",
       "1  0.057911  0.720676  0.527638  0.154431  0.196256  0.181456  0.008249   \n",
       "2  0.005774  0.802569  0.265598  0.109704  0.479232  0.165710  0.003776   \n",
       "3  0.000000  0.865730  0.268860  0.123676  0.164005  0.117761  0.001366   \n",
       "4  0.014686  0.327991  0.195815  0.090565  0.905646  0.113083  0.000583   \n",
       "\n",
       "          7  \n",
       "0  0.170510  \n",
       "1  0.321731  \n",
       "2  0.127025  \n",
       "3  0.349518  \n",
       "4  0.112594  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer()\n",
    "scaler.fit(train_set)\n",
    "train_set_scaled = scaler.transform(train_set)\n",
    "test_set_scaled = scaler.transform(test_set)\n",
    "\n",
    "df = pd.DataFrame(data=train_set_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"diabetes_impute_normalizer.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_impute_scaling_std.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.6845 - acc: 0.5703\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6577 - acc: 0.6510\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6421 - acc: 0.6523\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.6139 - acc: 0.6745\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5844 - acc: 0.7044\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5459 - acc: 0.7461\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5130 - acc: 0.7539\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4956 - acc: 0.7643\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4819 - acc: 0.7695\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4733 - acc: 0.7786\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4662 - acc: 0.7786\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4629 - acc: 0.7891\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4588 - acc: 0.7812\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 243us/step - loss: 0.4605 - acc: 0.7904\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4556 - acc: 0.7826\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4521 - acc: 0.7943\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4543 - acc: 0.7865\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4520 - acc: 0.7760\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4511 - acc: 0.7812\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4487 - acc: 0.7852\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4497 - acc: 0.7734\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4488 - acc: 0.7917\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4493 - acc: 0.7917\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4481 - acc: 0.7904\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4467 - acc: 0.7760\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4455 - acc: 0.7865\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4461 - acc: 0.7826\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4460 - acc: 0.7773\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4472 - acc: 0.7826\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4467 - acc: 0.7930\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4434 - acc: 0.7839\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4465 - acc: 0.7878\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4454 - acc: 0.7891\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4430 - acc: 0.7891\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4419 - acc: 0.7891\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4438 - acc: 0.7826\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4398 - acc: 0.7930\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4477 - acc: 0.7878\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4421 - acc: 0.7812\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4419 - acc: 0.7852\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4414 - acc: 0.7839\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4416 - acc: 0.7943\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4419 - acc: 0.7812\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4408 - acc: 0.7826\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4414 - acc: 0.7812\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4386 - acc: 0.7734\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4382 - acc: 0.7891\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4413 - acc: 0.7826\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4388 - acc: 0.7891\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4377 - acc: 0.7812\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4376 - acc: 0.7865\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4389 - acc: 0.7852\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4368 - acc: 0.7878\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4373 - acc: 0.7917\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4350 - acc: 0.7904\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4397 - acc: 0.7891\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4368 - acc: 0.7904\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4372 - acc: 0.7839\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4366 - acc: 0.7852\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.4343 - acc: 0.7878\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4355 - acc: 0.7839\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4364 - acc: 0.7878\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4329 - acc: 0.7878\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4362 - acc: 0.7891\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4339 - acc: 0.7826\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4361 - acc: 0.7773\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4318 - acc: 0.7969\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4330 - acc: 0.7904\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4348 - acc: 0.7852\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4329 - acc: 0.7852\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4311 - acc: 0.7878\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4309 - acc: 0.7865\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4353 - acc: 0.7878\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4305 - acc: 0.7943\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4345 - acc: 0.7826\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4297 - acc: 0.7956\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4311 - acc: 0.7852\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4338 - acc: 0.7786\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4283 - acc: 0.7826\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4320 - acc: 0.7891\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4281 - acc: 0.7930\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4313 - acc: 0.7956\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4283 - acc: 0.7904\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4294 - acc: 0.7930\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4317 - acc: 0.7865\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4293 - acc: 0.7812\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4278 - acc: 0.7917\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4308 - acc: 0.7812\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4298 - acc: 0.7917\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4282 - acc: 0.7865\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4254 - acc: 0.7878\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4294 - acc: 0.7969\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4287 - acc: 0.7865\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4274 - acc: 0.7865\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4307 - acc: 0.7865\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4311 - acc: 0.7839\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4265 - acc: 0.7956\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4276 - acc: 0.7930\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4285 - acc: 0.7904\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4270 - acc: 0.7943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f20daf4518>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 285us/step\n",
      "\n",
      "acc: 79.69%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "\n",
    "median_bmi = dataset['BMI'].median()\n",
    "dataset['BMI'] = dataset['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)\n",
    "\n",
    "median_bloodp = dataset['BloodPressure'].median()\n",
    "dataset['BloodPressure'] = dataset['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)\n",
    "\n",
    "median_plglcconc = dataset['Glucose'].median()\n",
    "dataset['Glucose'] = dataset['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)\n",
    "\n",
    "median_skinthick = dataset['SkinThickness'].median()\n",
    "dataset['SkinThickness'] = dataset['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)\n",
    "\n",
    "median_Insulin = dataset['Insulin'].median()\n",
    "dataset['Insulin'] = dataset['Insulin'].replace(\n",
    "    to_replace=0, value=median_Insulin)\n",
    "\n",
    "median_DiabetesPedigreeFunction = dataset['DiabetesPedigreeFunction'].median()\n",
    "dataset['DiabetesPedigreeFunction'] = dataset['DiabetesPedigreeFunction'].replace(\n",
    "    to_replace=0, value=median_DiabetesPedigreeFunction)\n",
    "\n",
    "median_Age = dataset['Age'].median()\n",
    "dataset['Age'] = dataset['Age'].replace(\n",
    "    to_replace=0, value=median_Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(\n",
    "    dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set_labels = train_set[\"Outcome\"].copy()\n",
    "train_set = train_set.drop(\"Outcome\", axis=1)\n",
    "\n",
    "test_set_labels = test_set[\"Outcome\"].copy()\n",
    "test_set = test_set.drop(\"Outcome\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nazmus Sakib\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.282209</td>\n",
       "      <td>0.096499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.438710</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.204499</td>\n",
       "      <td>0.514091</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>0.214724</td>\n",
       "      <td>0.245944</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754839</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.075665</td>\n",
       "      <td>0.075149</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.572597</td>\n",
       "      <td>0.068318</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.117647  0.258065  0.489796  0.272727  0.019832  0.282209  0.096499   \n",
       "1  0.529412  0.438710  0.591837  0.290909  0.019832  0.204499  0.514091   \n",
       "2  0.058824  0.612903  0.224490  0.200000  0.082933  0.214724  0.245944   \n",
       "3  0.000000  0.754839  0.265306  0.272727  0.019832  0.075665  0.075149   \n",
       "4  0.352941  0.580645  0.571429  0.527273  0.427885  0.572597  0.068318   \n",
       "\n",
       "          7  \n",
       "0  0.000000  \n",
       "1  0.483333  \n",
       "2  0.016667  \n",
       "3  0.733333  \n",
       "4  0.416667  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler as Scaler\n",
    "\n",
    "scaler = Scaler()\n",
    "scaler.fit(train_set)\n",
    "train_set_scaled = scaler.transform(train_set)\n",
    "test_set_scaled = scaler.transform(test_set)\n",
    "\n",
    "df = pd.DataFrame(data=train_set_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.6889 - acc: 0.5781\n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6538 - acc: 0.6510\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.6339 - acc: 0.6510\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.6296 - acc: 0.6510\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6252 - acc: 0.6576\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.6199 - acc: 0.6563\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6150 - acc: 0.6589\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6129 - acc: 0.6523\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 0s 217us/step - loss: 0.6080 - acc: 0.6576\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6065 - acc: 0.6497\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6047 - acc: 0.6654\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.6034 - acc: 0.6563\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6021 - acc: 0.6680\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6019 - acc: 0.6589\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5995 - acc: 0.6628\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6004 - acc: 0.6589\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5979 - acc: 0.6667\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5957 - acc: 0.6719\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5962 - acc: 0.6693\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5944 - acc: 0.6706\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5961 - acc: 0.6771\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5925 - acc: 0.6797\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5946 - acc: 0.6771\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5892 - acc: 0.6823\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5974 - acc: 0.6758\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5927 - acc: 0.6784\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5928 - acc: 0.6758\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5918 - acc: 0.6667\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5904 - acc: 0.6784\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5905 - acc: 0.6784\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5894 - acc: 0.6849\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5902 - acc: 0.6875\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5908 - acc: 0.6823\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5897 - acc: 0.6732\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5897 - acc: 0.6888\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5892 - acc: 0.6680\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5871 - acc: 0.6836\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5888 - acc: 0.6758\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5870 - acc: 0.6797\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5837 - acc: 0.6875\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5880 - acc: 0.6810\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5857 - acc: 0.6888\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5845 - acc: 0.6875\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5860 - acc: 0.6927\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5843 - acc: 0.6940\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5844 - acc: 0.6927\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5843 - acc: 0.6927\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5824 - acc: 0.6901\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5834 - acc: 0.6784\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5829 - acc: 0.6875\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5824 - acc: 0.6927\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5823 - acc: 0.6862\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5810 - acc: 0.6836\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5815 - acc: 0.6875\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5788 - acc: 0.6927\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5829 - acc: 0.6836\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5790 - acc: 0.6810\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5802 - acc: 0.6862\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5795 - acc: 0.6823\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.5799 - acc: 0.6940\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5784 - acc: 0.6849\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5843 - acc: 0.6797\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.5784 - acc: 0.6940\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5802 - acc: 0.6797\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5785 - acc: 0.6836\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5781 - acc: 0.6953\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5792 - acc: 0.6875\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5785 - acc: 0.6875\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5764 - acc: 0.6823\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5770 - acc: 0.6836\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5783 - acc: 0.6862\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5749 - acc: 0.6823\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 0s 238us/step - loss: 0.5761 - acc: 0.6810\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5765 - acc: 0.6875\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5759 - acc: 0.6732\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5740 - acc: 0.6836\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5731 - acc: 0.6927\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5729 - acc: 0.6849\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5731 - acc: 0.6888\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5722 - acc: 0.6797\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5727 - acc: 0.6927\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5718 - acc: 0.6901\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5693 - acc: 0.6901\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5721 - acc: 0.6862\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5712 - acc: 0.6849\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5731 - acc: 0.6823\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5721 - acc: 0.6823\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5690 - acc: 0.6927\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5685 - acc: 0.6888\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5682 - acc: 0.6914\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5656 - acc: 0.6953\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5665 - acc: 0.6979\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5663 - acc: 0.6862\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5665 - acc: 0.6862\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5686 - acc: 0.6927\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5678 - acc: 0.6849\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5651 - acc: 0.6888\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5657 - acc: 0.6823\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5652 - acc: 0.6914\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5651 - acc: 0.6888\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5638 - acc: 0.6888\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5631 - acc: 0.7018\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5657 - acc: 0.6875\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5641 - acc: 0.6953\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5636 - acc: 0.6927\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5640 - acc: 0.7018\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5609 - acc: 0.6862\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5599 - acc: 0.6966\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5625 - acc: 0.6940\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5601 - acc: 0.6888\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5594 - acc: 0.6992\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5608 - acc: 0.6979\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5608 - acc: 0.6914\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5597 - acc: 0.7031\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5616 - acc: 0.6953\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5581 - acc: 0.7044\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5625 - acc: 0.7018\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5588 - acc: 0.6979\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5585 - acc: 0.6914\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5605 - acc: 0.7031\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 0s 254us/step - loss: 0.5587 - acc: 0.7031\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5607 - acc: 0.7018\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5574 - acc: 0.7018\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5571 - acc: 0.7031\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5567 - acc: 0.7031\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5568 - acc: 0.7031\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5569 - acc: 0.7057\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5568 - acc: 0.6953\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5543 - acc: 0.6992\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5564 - acc: 0.7044\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5551 - acc: 0.7096\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5556 - acc: 0.7057\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5561 - acc: 0.7109\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5555 - acc: 0.7083\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5568 - acc: 0.7044\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5549 - acc: 0.6966\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5553 - acc: 0.7161\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5538 - acc: 0.7135\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5529 - acc: 0.7135\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5541 - acc: 0.7135\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5556 - acc: 0.6979\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5546 - acc: 0.7070\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5552 - acc: 0.7096\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5539 - acc: 0.7057\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5526 - acc: 0.7135\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5551 - acc: 0.7161\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5532 - acc: 0.7031\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5523 - acc: 0.7135\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5516 - acc: 0.7018\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5507 - acc: 0.7057\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5528 - acc: 0.7083\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5496 - acc: 0.7135\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5523 - acc: 0.6979\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5515 - acc: 0.7096\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5500 - acc: 0.7057\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5511 - acc: 0.7083\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5516 - acc: 0.7057\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5501 - acc: 0.7044\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5527 - acc: 0.7031\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5530 - acc: 0.7057\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.5500 - acc: 0.7187\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5467 - acc: 0.7214\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5563 - acc: 0.6979\n",
      "Epoch 164/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5507 - acc: 0.7057\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 244us/step - loss: 0.5503 - acc: 0.7135\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5498 - acc: 0.7109\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5505 - acc: 0.7044\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.5480 - acc: 0.7096\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 0s 156us/step - loss: 0.5496 - acc: 0.7031\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5485 - acc: 0.7188 0s - loss: 0.5502 - acc: 0.72\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5489 - acc: 0.7148\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5473 - acc: 0.7148\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5512 - acc: 0.7148\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5508 - acc: 0.7174\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5488 - acc: 0.7122\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5486 - acc: 0.7057\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5504 - acc: 0.7018\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5474 - acc: 0.7174\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5454 - acc: 0.7161\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5488 - acc: 0.7083\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5464 - acc: 0.7148\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5458 - acc: 0.7109\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5476 - acc: 0.7214\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5459 - acc: 0.7070\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5441 - acc: 0.7201\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5469 - acc: 0.7214\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5493 - acc: 0.7161\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5503 - acc: 0.7070\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5466 - acc: 0.7135\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5477 - acc: 0.7109\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5521 - acc: 0.7031\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5467 - acc: 0.7148\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5435 - acc: 0.7083\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5438 - acc: 0.7096\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5458 - acc: 0.7161\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5436 - acc: 0.7227\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5440 - acc: 0.7201\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5459 - acc: 0.7161\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5451 - acc: 0.7201\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5461 - acc: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f211aacf28>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_impute_normalization_std.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 20us/step\n",
      "\n",
      "acc: 71.88%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "\n",
    "median_bmi = dataset['BMI'].mean()\n",
    "dataset['BMI'] = dataset['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)\n",
    "\n",
    "median_bloodp = dataset['BloodPressure'].mean()\n",
    "dataset['BloodPressure'] = dataset['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)\n",
    "\n",
    "median_plglcconc = dataset['Glucose'].mean()\n",
    "dataset['Glucose'] = dataset['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)\n",
    "\n",
    "median_skinthick = dataset['SkinThickness'].mean()\n",
    "dataset['SkinThickness'] = dataset['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)\n",
    "\n",
    "median_Insulin = dataset['Insulin'].mean()\n",
    "dataset['Insulin'] = dataset['Insulin'].replace(\n",
    "    to_replace=0, value=median_Insulin)\n",
    "\n",
    "median_DiabetesPedigreeFunction = dataset['DiabetesPedigreeFunction'].mean()\n",
    "dataset['DiabetesPedigreeFunction'] = dataset['DiabetesPedigreeFunction'].replace(\n",
    "    to_replace=0, value=median_DiabetesPedigreeFunction)\n",
    "\n",
    "median_Age = dataset['Age'].mean()\n",
    "dataset['Age'] = dataset['Age'].replace(\n",
    "    to_replace=0, value=median_Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(\n",
    "    dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set_labels = train_set[\"Outcome\"].copy()\n",
    "train_set = train_set.drop(\"Outcome\", axis=1)\n",
    "\n",
    "test_set_labels = test_set[\"Outcome\"].copy()\n",
    "test_set = test_set.drop(\"Outcome\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"diabetes_impute_mean.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 4.0752 - acc: 0.5508 \n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.9117 - acc: 0.6602\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.7790 - acc: 0.6784\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.7409 - acc: 0.6745\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.6817 - acc: 0.6654\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6874 - acc: 0.6797\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.6656 - acc: 0.6810\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.6625 - acc: 0.6940\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.6164 - acc: 0.7096\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6262 - acc: 0.6823\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6335 - acc: 0.6888\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.6261 - acc: 0.7044\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 0s 346us/step - loss: 0.6151 - acc: 0.6875 0s - loss: 0.5753 - acc: 0.7\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.6183 - acc: 0.7109\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.6100 - acc: 0.6888\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5932 - acc: 0.7122\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6015 - acc: 0.7018\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5781 - acc: 0.7070\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5953 - acc: 0.7188\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5845 - acc: 0.7057\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5945 - acc: 0.6966\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5741 - acc: 0.7201\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5858 - acc: 0.7057\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5925 - acc: 0.7096\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5754 - acc: 0.7083\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5601 - acc: 0.7240\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5950 - acc: 0.6979\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5674 - acc: 0.7188\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5537 - acc: 0.7305\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5605 - acc: 0.7201\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5590 - acc: 0.7122\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5621 - acc: 0.7240\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5606 - acc: 0.7201\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5642 - acc: 0.7253\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5580 - acc: 0.7096\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5511 - acc: 0.7240\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5617 - acc: 0.7253\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5473 - acc: 0.7422\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5526 - acc: 0.7279\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5591 - acc: 0.7318\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5396 - acc: 0.7201\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5454 - acc: 0.7370\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5398 - acc: 0.7487\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5325 - acc: 0.7266\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5333 - acc: 0.7500\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5432 - acc: 0.7305\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5529 - acc: 0.7318\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5500 - acc: 0.7370\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5366 - acc: 0.7383\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5425 - acc: 0.7253\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5226 - acc: 0.7435\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5328 - acc: 0.7305\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5319 - acc: 0.7422\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5251 - acc: 0.7344\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5308 - acc: 0.7318\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5441 - acc: 0.7318\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5405 - acc: 0.7435\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5187 - acc: 0.7513\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5178 - acc: 0.7396\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5216 - acc: 0.7461\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5222 - acc: 0.7448\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.5073 - acc: 0.7357\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5207 - acc: 0.7435\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5222 - acc: 0.7435\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5181 - acc: 0.7513\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5109 - acc: 0.7487\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5222 - acc: 0.7552\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5170 - acc: 0.7448\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5062 - acc: 0.7383\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5195 - acc: 0.7461\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5418 - acc: 0.7409\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5193 - acc: 0.7435\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5155 - acc: 0.7448\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5167 - acc: 0.7370\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5111 - acc: 0.7344\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5072 - acc: 0.7383\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5053 - acc: 0.7539\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5147 - acc: 0.7474\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4920 - acc: 0.7578\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5099 - acc: 0.7578\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5077 - acc: 0.7552\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5091 - acc: 0.7539\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5073 - acc: 0.7344\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5307 - acc: 0.7266\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4916 - acc: 0.7552\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.5114 - acc: 0.7474\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5085 - acc: 0.7513\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5016 - acc: 0.7513\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4999 - acc: 0.7630\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4980 - acc: 0.7617\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4937 - acc: 0.7708\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4880 - acc: 0.7565\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5185 - acc: 0.7435\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5115 - acc: 0.7591\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4935 - acc: 0.7656\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5033 - acc: 0.7500\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5039 - acc: 0.7448\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4949 - acc: 0.7526\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4993 - acc: 0.7526\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4919 - acc: 0.7565\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4987 - acc: 0.7526\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4906 - acc: 0.7643\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4913 - acc: 0.7526\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5044 - acc: 0.7539\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4887 - acc: 0.7578\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4957 - acc: 0.7708\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4982 - acc: 0.7500\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4750 - acc: 0.7734\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4818 - acc: 0.7734\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4870 - acc: 0.7721\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5036 - acc: 0.7500\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4893 - acc: 0.7682\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5019 - acc: 0.7669\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4827 - acc: 0.7669\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4901 - acc: 0.7487\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4869 - acc: 0.7526\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4832 - acc: 0.7708\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4857 - acc: 0.7604\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4920 - acc: 0.7643\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4933 - acc: 0.7565\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.4825 - acc: 0.7682\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4858 - acc: 0.7604\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4849 - acc: 0.7513\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4926 - acc: 0.7552\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4822 - acc: 0.7565\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4805 - acc: 0.7708\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.4793 - acc: 0.7643\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4975 - acc: 0.7656\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4847 - acc: 0.7539\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4877 - acc: 0.7669\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4844 - acc: 0.7656\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4825 - acc: 0.7695\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4855 - acc: 0.7526\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4842 - acc: 0.7617\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4788 - acc: 0.7630\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4872 - acc: 0.7643\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4769 - acc: 0.7591\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4734 - acc: 0.7630\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4861 - acc: 0.7656\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4924 - acc: 0.7526\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4857 - acc: 0.7617\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4949 - acc: 0.7552\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4927 - acc: 0.7500\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4789 - acc: 0.7552\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4790 - acc: 0.7682\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4765 - acc: 0.7617\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4823 - acc: 0.7630\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4730 - acc: 0.7578\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4761 - acc: 0.7617\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4681 - acc: 0.7708\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4756 - acc: 0.7591\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4751 - acc: 0.7656\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4758 - acc: 0.7591\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4881 - acc: 0.7526\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4820 - acc: 0.7591\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4780 - acc: 0.7656\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4875 - acc: 0.7682\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4688 - acc: 0.7708\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4775 - acc: 0.7604\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4815 - acc: 0.7539\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4830 - acc: 0.7578\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4726 - acc: 0.7682\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 0s 346us/step - loss: 0.4796 - acc: 0.7500\n",
      "Epoch 164/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4796 - acc: 0.7578\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 224us/step - loss: 0.4800 - acc: 0.7591\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4807 - acc: 0.7695\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4753 - acc: 0.7747\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.4774 - acc: 0.7708\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4802 - acc: 0.7500\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4737 - acc: 0.7630\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4780 - acc: 0.7604\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4863 - acc: 0.7708\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4781 - acc: 0.7708\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4788 - acc: 0.7617\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4765 - acc: 0.7513\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4738 - acc: 0.7682\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4899 - acc: 0.7643\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4810 - acc: 0.7682\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4716 - acc: 0.7500\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4847 - acc: 0.7500\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4741 - acc: 0.7591\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4751 - acc: 0.7656\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4757 - acc: 0.7656\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4747 - acc: 0.7682\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4753 - acc: 0.7526\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4759 - acc: 0.7786\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4828 - acc: 0.7565\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4718 - acc: 0.7565\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4643 - acc: 0.7747\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4787 - acc: 0.7526\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4774 - acc: 0.7591\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4601 - acc: 0.7695\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4792 - acc: 0.7500\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4696 - acc: 0.7734\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4732 - acc: 0.7643\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4606 - acc: 0.7708\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4623 - acc: 0.7734\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4805 - acc: 0.7526\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4811 - acc: 0.7539\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4668 - acc: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3b6b3e390>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_impute_mean.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 346us/step\n",
      "\n",
      "acc: 71.09%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "\n",
    "median_bmi = dataset['BMI'].std()\n",
    "dataset['BMI'] = dataset['BMI'].replace(\n",
    "    to_replace=0, value=median_bmi)\n",
    "\n",
    "median_bloodp = dataset['BloodPressure'].std()\n",
    "dataset['BloodPressure'] = dataset['BloodPressure'].replace(\n",
    "    to_replace=0, value=median_bloodp)\n",
    "\n",
    "median_plglcconc = dataset['Glucose'].std()\n",
    "dataset['Glucose'] = dataset['Glucose'].replace(\n",
    "    to_replace=0, value=median_plglcconc)\n",
    "\n",
    "median_skinthick = dataset['SkinThickness'].std()\n",
    "dataset['SkinThickness'] = dataset['SkinThickness'].replace(\n",
    "    to_replace=0, value=median_skinthick)\n",
    "\n",
    "median_Insulin = dataset['Insulin'].std()\n",
    "dataset['Insulin'] = dataset['Insulin'].replace(\n",
    "    to_replace=0, value=median_Insulin)\n",
    "\n",
    "median_DiabetesPedigreeFunction = dataset['DiabetesPedigreeFunction'].std()\n",
    "dataset['DiabetesPedigreeFunction'] = dataset['DiabetesPedigreeFunction'].replace(\n",
    "    to_replace=0, value=median_DiabetesPedigreeFunction)\n",
    "\n",
    "median_Age = dataset['Age'].std()\n",
    "dataset['Age'] = dataset['Age'].replace(\n",
    "    to_replace=0, value=median_Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"diabetes_impute_std.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 2.7641 - acc: 0.5247\n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.9772 - acc: 0.5924\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.7481 - acc: 0.6602\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.7422 - acc: 0.6602\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.6750 - acc: 0.6797\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.7071 - acc: 0.6810\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6635 - acc: 0.6758\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.7024 - acc: 0.6641\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6379 - acc: 0.6771\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6543 - acc: 0.6849\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6270 - acc: 0.6914\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6555 - acc: 0.6810\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6325 - acc: 0.6901\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6518 - acc: 0.6706\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6165 - acc: 0.7005\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6376 - acc: 0.7044\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6239 - acc: 0.6914\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6404 - acc: 0.6745\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5947 - acc: 0.7096\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5872 - acc: 0.7240\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6013 - acc: 0.7135\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5851 - acc: 0.7227\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5831 - acc: 0.7070\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5819 - acc: 0.7148\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.5760 - acc: 0.7083\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5746 - acc: 0.7057\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5974 - acc: 0.7227\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5666 - acc: 0.7266\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5581 - acc: 0.7083\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5571 - acc: 0.7370\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5676 - acc: 0.7266\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5537 - acc: 0.7227\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5550 - acc: 0.7318\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5505 - acc: 0.7435\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5320 - acc: 0.7422\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5521 - acc: 0.7318\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5733 - acc: 0.7018\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5638 - acc: 0.7318\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5282 - acc: 0.7435\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5338 - acc: 0.7513\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5577 - acc: 0.7357\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5381 - acc: 0.7292\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5327 - acc: 0.7305\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5202 - acc: 0.7500\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5294 - acc: 0.7461\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5240 - acc: 0.7591\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5296 - acc: 0.7552\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5119 - acc: 0.7565\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5160 - acc: 0.7604\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5402 - acc: 0.7318\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5039 - acc: 0.7604\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5174 - acc: 0.7474\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5059 - acc: 0.7396\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5114 - acc: 0.7461\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5145 - acc: 0.7526\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5117 - acc: 0.7370\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5219 - acc: 0.7591\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5250 - acc: 0.7435\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5047 - acc: 0.7487\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5129 - acc: 0.7643\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5023 - acc: 0.7604\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4885 - acc: 0.7747\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5005 - acc: 0.7682\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4990 - acc: 0.7604\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4960 - acc: 0.7526\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4973 - acc: 0.7591\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5004 - acc: 0.7617\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4960 - acc: 0.7682\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4862 - acc: 0.7708\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4770 - acc: 0.7643\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4912 - acc: 0.7617\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4893 - acc: 0.7669\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4853 - acc: 0.7500\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4716 - acc: 0.7721\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4846 - acc: 0.7630\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4847 - acc: 0.7630\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4955 - acc: 0.7878\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4861 - acc: 0.7773\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4756 - acc: 0.7799\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4694 - acc: 0.7786\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4816 - acc: 0.7852\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4753 - acc: 0.7799\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4845 - acc: 0.7695\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4864 - acc: 0.7721\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4649 - acc: 0.7826\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4706 - acc: 0.7799\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4704 - acc: 0.7812\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4752 - acc: 0.7747\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4791 - acc: 0.7721\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4714 - acc: 0.7839\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4790 - acc: 0.7669\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4692 - acc: 0.7799\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4664 - acc: 0.7708\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4630 - acc: 0.7852\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4679 - acc: 0.7904\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4616 - acc: 0.7865\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4738 - acc: 0.7695\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4716 - acc: 0.7669\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4685 - acc: 0.7773\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4682 - acc: 0.7773\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4769 - acc: 0.7682\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4765 - acc: 0.7721\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 0s 346us/step - loss: 0.4626 - acc: 0.7852\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 0s 263us/step - loss: 0.4740 - acc: 0.7695\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.4677 - acc: 0.7760\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4588 - acc: 0.7669\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4865 - acc: 0.7669\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4595 - acc: 0.7878\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4565 - acc: 0.7956\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4773 - acc: 0.7721\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4578 - acc: 0.7904\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4603 - acc: 0.7799\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4583 - acc: 0.7799\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4589 - acc: 0.7786\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4804 - acc: 0.7799\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4678 - acc: 0.7878\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4660 - acc: 0.7773\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4513 - acc: 0.7930\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4585 - acc: 0.7812\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4828 - acc: 0.7643\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4683 - acc: 0.7760\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4536 - acc: 0.7865\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4681 - acc: 0.7799\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4504 - acc: 0.7839\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4649 - acc: 0.7826\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4747 - acc: 0.7747\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4466 - acc: 0.7865\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4476 - acc: 0.8008\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4494 - acc: 0.7917\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4577 - acc: 0.7708\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4496 - acc: 0.7839\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4566 - acc: 0.7839\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4608 - acc: 0.7878\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4701 - acc: 0.7747\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4581 - acc: 0.7839\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4442 - acc: 0.7904\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4545 - acc: 0.7839\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4534 - acc: 0.7904\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4572 - acc: 0.7839\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4499 - acc: 0.7878\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4613 - acc: 0.7891\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4578 - acc: 0.7812\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4733 - acc: 0.7708\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4568 - acc: 0.7747\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4591 - acc: 0.7799\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4580 - acc: 0.7852\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4604 - acc: 0.7773\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4679 - acc: 0.7865\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4516 - acc: 0.7826\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4571 - acc: 0.7904\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4550 - acc: 0.7943\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4581 - acc: 0.7852\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4522 - acc: 0.7839\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4608 - acc: 0.7891\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4517 - acc: 0.7891\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4462 - acc: 0.7891\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4601 - acc: 0.7917\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4493 - acc: 0.7917\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4627 - acc: 0.7786 0s - loss: 0.4433 - acc: 0.79\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4467 - acc: 0.7891\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4353 - acc: 0.7956\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4478 - acc: 0.7878\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4539 - acc: 0.7734\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 180us/step - loss: 0.4493 - acc: 0.7852\n",
      "Epoch 165/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4473 - acc: 0.7956\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4575 - acc: 0.7904\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4621 - acc: 0.7917\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.4512 - acc: 0.7904\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.4481 - acc: 0.7904\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4687 - acc: 0.7734\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4615 - acc: 0.7852\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4506 - acc: 0.7865\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4591 - acc: 0.7891\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4613 - acc: 0.7826\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.4379 - acc: 0.781 - 0s 163us/step - loss: 0.4432 - acc: 0.7799\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4467 - acc: 0.7812\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4387 - acc: 0.7982\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4495 - acc: 0.7799\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4425 - acc: 0.8099\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4636 - acc: 0.7839\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4595 - acc: 0.7865\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4444 - acc: 0.7865\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4530 - acc: 0.7852\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4486 - acc: 0.7839\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4616 - acc: 0.7891\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4527 - acc: 0.7865\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4620 - acc: 0.7786\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4521 - acc: 0.7826\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4537 - acc: 0.7799\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4537 - acc: 0.7760\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4402 - acc: 0.8008\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4590 - acc: 0.7917\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4566 - acc: 0.7865\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4507 - acc: 0.7930\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4421 - acc: 0.7865\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4524 - acc: 0.7799\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4391 - acc: 0.7852\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4401 - acc: 0.7852\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4512 - acc: 0.7995\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4525 - acc: 0.7839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3b85245f8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_impute_std.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 468us/step\n",
      "\n",
      "acc: 80.86%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"diabetes_impute_std.txt\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-15.46505896 -32.15983414]\n",
      " [-26.35415787  32.55551479]\n",
      " [-10.77178388 -61.45464328]\n",
      " ...\n",
      " [-23.77110352  -3.39778147]\n",
      " [-19.82236876  -8.06381502]\n",
      " [-24.98538077  25.04875082]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2).fit(X)\n",
    "train_set = pca.transform(X)\n",
    "\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 4.4352 - acc: 0.4909\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.7078 - acc: 0.6523\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6611 - acc: 0.6615\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6559 - acc: 0.6589\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6495 - acc: 0.6602\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6450 - acc: 0.6628\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6485 - acc: 0.6654\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6396 - acc: 0.6667\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6311 - acc: 0.6680\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6290 - acc: 0.6784\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6238 - acc: 0.6810\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6235 - acc: 0.6797\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6231 - acc: 0.6732\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6121 - acc: 0.6927\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.6096 - acc: 0.6901\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.6045 - acc: 0.7005\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.6029 - acc: 0.7083\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6015 - acc: 0.7083\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6034 - acc: 0.6966\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5999 - acc: 0.7018\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5934 - acc: 0.6992\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5930 - acc: 0.7031\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5887 - acc: 0.7122\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5844 - acc: 0.7161\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5826 - acc: 0.7109\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5731 - acc: 0.7292\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5740 - acc: 0.7266\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5693 - acc: 0.7331\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5654 - acc: 0.7201\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.5680 - acc: 0.705 - 0s 203us/step - loss: 0.5698 - acc: 0.7096\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5654 - acc: 0.7240\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5606 - acc: 0.7487\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5587 - acc: 0.7201\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5556 - acc: 0.7201\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5533 - acc: 0.7370\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5520 - acc: 0.7253\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5483 - acc: 0.7318\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5465 - acc: 0.7331\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5458 - acc: 0.7253\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5413 - acc: 0.7396\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5405 - acc: 0.7357\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5431 - acc: 0.7357\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5373 - acc: 0.7409\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5316 - acc: 0.7409\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5371 - acc: 0.7318\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5296 - acc: 0.7448\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5310 - acc: 0.7500\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5305 - acc: 0.7474\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5242 - acc: 0.7539\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.5252 - acc: 0.7578\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5265 - acc: 0.7474\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5205 - acc: 0.7383\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5167 - acc: 0.7682\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5139 - acc: 0.7500\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5208 - acc: 0.7552\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5224 - acc: 0.7591\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5217 - acc: 0.7487\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5277 - acc: 0.7422\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5184 - acc: 0.7578\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5188 - acc: 0.7591\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5145 - acc: 0.7630\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5206 - acc: 0.7487\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5119 - acc: 0.7630\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5124 - acc: 0.7578\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5139 - acc: 0.7591\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5124 - acc: 0.7513\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5092 - acc: 0.7656\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5130 - acc: 0.7578\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5096 - acc: 0.7539\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5038 - acc: 0.7695\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5120 - acc: 0.7591\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5114 - acc: 0.7552\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5053 - acc: 0.7643\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5064 - acc: 0.7682\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5078 - acc: 0.7721\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 209us/step - loss: 0.5066 - acc: 0.7565\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5111 - acc: 0.7578\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5031 - acc: 0.7617\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5070 - acc: 0.7695\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5004 - acc: 0.7786\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5036 - acc: 0.7656\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5026 - acc: 0.7656\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5006 - acc: 0.7565\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5004 - acc: 0.7682\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4987 - acc: 0.7682\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5020 - acc: 0.7682\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4999 - acc: 0.7617\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4947 - acc: 0.7695\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5030 - acc: 0.7591\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4908 - acc: 0.7656\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4956 - acc: 0.7643\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4993 - acc: 0.7552\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4916 - acc: 0.7630\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4927 - acc: 0.7695\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4939 - acc: 0.7617\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4926 - acc: 0.7604\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4905 - acc: 0.7604\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4888 - acc: 0.7669\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4889 - acc: 0.7747\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4881 - acc: 0.7682\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4912 - acc: 0.7747\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4866 - acc: 0.7669\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4899 - acc: 0.7669\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4985 - acc: 0.7669\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4882 - acc: 0.7734\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4829 - acc: 0.7826\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4924 - acc: 0.7747\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4837 - acc: 0.7734\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4864 - acc: 0.7682\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4887 - acc: 0.7695\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4873 - acc: 0.7617\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4894 - acc: 0.7617\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4861 - acc: 0.7747\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4854 - acc: 0.7734\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4875 - acc: 0.7604\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4818 - acc: 0.7812\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4764 - acc: 0.7760\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4837 - acc: 0.7669\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4844 - acc: 0.7695\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4800 - acc: 0.7786\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4760 - acc: 0.7695\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4757 - acc: 0.7747\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4820 - acc: 0.7682\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4787 - acc: 0.7760\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4832 - acc: 0.7591\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4741 - acc: 0.7734\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4838 - acc: 0.7734\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4733 - acc: 0.7747\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.4783 - acc: 0.7695\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4760 - acc: 0.7786\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4791 - acc: 0.7630\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4848 - acc: 0.7917\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4787 - acc: 0.7708\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4785 - acc: 0.7773\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4776 - acc: 0.7682\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4778 - acc: 0.7773\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4757 - acc: 0.7786\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4754 - acc: 0.7747\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4755 - acc: 0.7604\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4861 - acc: 0.7552\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4766 - acc: 0.7773\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4724 - acc: 0.7799\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4780 - acc: 0.7617\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4808 - acc: 0.7578\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4685 - acc: 0.7721\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4703 - acc: 0.7773\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4660 - acc: 0.7695\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4770 - acc: 0.7760\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4751 - acc: 0.7799\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4654 - acc: 0.7904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f214f44d30>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 427us/step\n",
      "\n",
      "acc: 78.91%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
